{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Najlalala007/Machine-Learning/blob/main/ML_Task10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "v2Bw_wXXQKaf"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pyglet==1.5.1\n",
        "!apt install python-opengl\n",
        "!apt install ffmpeg\n",
        "!apt install xvfb\n",
        "!pip3 install pyvirtualdisplay\n",
        "\n",
        "# Virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "oYbPDSFYQhwd"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install gym==0.24\n",
        "!pip install pygame\n",
        "!pip install numpy\n",
        "\n",
        "!pip install imageio imageio_ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "twtBNh1WQ3EF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import random\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-hUKLnhQ_pf",
        "outputId": "3cad2f74-108f-422d-fd09-3d97132ba1ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "my_map = [\n",
        "    \"FHFS\",\n",
        "    \"SHHF\",\n",
        "    \"FFHF\",\n",
        "    \"HGFF\"\n",
        "]\n",
        "\n",
        "env = gym.make('FrozenLake-v1', desc=my_map, is_slippery=False)\n",
        "env.render()\n",
        "env.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoAGkxOCUCej",
        "outputId": "d2898aa8-a21d-40ed-afba-d396c1121e3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action_space_size = 4\n",
            "state_space_size = 16\n",
            "q_table = \n",
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "action_space_size = env.action_space.n\n",
        "state_space_size = env.observation_space.n\n",
        "q_table = np.zeros((state_space_size, action_space_size))\n",
        "print(f'action_space_size = {action_space_size}')\n",
        "print(f'state_space_size = {state_space_size}')\n",
        "print(f'q_table = \\n{q_table}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ravyEYVNVXsq"
      },
      "outputs": [],
      "source": [
        "# Training parameters\n",
        "num_episodes = 2000\n",
        "max_steps_per_episode = 30\n",
        "learning_rate = 0.1\n",
        "discount_rate = 0.99\n",
        "\n",
        "exploration_rate =1\n",
        "max_exploration_rate = 1\n",
        "min_exploration_rate = 0.01\n",
        "exploration_decay_rate = 0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nr48_17XqBk",
        "outputId": "192660e5-daa3-45a9-c449-69ab13362141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1890 episode and 0 step\n",
            "Delta Q = 0.9730043629686648\n",
            "Q_table[0,1]_old = 0.8699943090288167\n",
            "Q_table[(0, 1)]_new = 0.8559992410945998\n",
            "We are on 0 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1890 episode and 1 step\n",
            "Delta Q = 0.9730043629686648\n",
            "Q_table[7,2]_old = 0.7175739717450026\n",
            "Q_table[(7, 2)]_new = 0.7188209375391671\n",
            "We are on 7 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1890 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1891 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,2]_old = 0.10311929480611291\n",
            "Q_table[(0, 2)]_new = 0.09280736532550163\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1892 episode and 0 step\n",
            "Delta Q = 0.9707707149887312\n",
            "Q_table[0,3]_old = 0.806665405316144\n",
            "Q_table[(0, 3)]_new = 0.7967695797732608\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1892 episode and 1 step\n",
            "Delta Q = 0.9707707149887312\n",
            "Q_table[3,2]_old = 0.6974082313466224\n",
            "Q_table[(3, 2)]_new = 0.6984381232006914\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1892 episode and 2 step\n",
            "Delta Q = 0.9730043629686648\n",
            "Q_table[3,1]_old = 0.7148557069568814\n",
            "Q_table[(3, 1)]_new = 0.716374499229858\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1892 episode and 3 step\n",
            "Delta Q = 0.975024415312434\n",
            "Q_table[7,1]_old = 0.7374178077642904\n",
            "Q_table[(7, 1)]_new = 0.7387004423002954\n",
            "We are on 7 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1892 episode and 4 step\n",
            "Delta Q = 0.9731313437877293\n",
            "Q_table[11,3]_old = 0.7002704650808969\n",
            "Q_table[(11, 3)]_new = 0.7033747623605364\n",
            "We are on 11 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1892 episode and 5 step\n",
            "Delta Q = 0.975024415312434\n",
            "Q_table[7,1]_old = 0.7387004423002954\n",
            "Q_table[(7, 1)]_new = 0.7398548133826999\n",
            "We are on 7 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1892 episode and 6 step\n",
            "Delta Q = 0.975024415312434\n",
            "Q_table[11,2]_old = 0.690078694752537\n",
            "Q_table[(11, 2)]_new = 0.6960952405897173\n",
            "We are on 11 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1892 episode and 7 step\n",
            "Delta Q = 0.9732456265248873\n",
            "Q_table[11,3]_old = 0.7033747623605364\n",
            "Q_table[(11, 3)]_new = 0.7062829126493702\n",
            "We are on 11 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1892 episode and 8 step\n",
            "Delta Q = 0.9709210754237559\n",
            "Q_table[7,3]_old = 0.6806639464048758\n",
            "Q_table[(7, 3)]_new = 0.6835186271881442\n",
            "We are on 7 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1892 episode and 9 step\n",
            "Delta Q = 0.9674124778965603\n",
            "Q_table[3,0]_old = 0.6627411399611042\n",
            "Q_table[(3, 0)]_new = 0.663879503861554\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1892 episode and 10 step\n",
            "Delta Q = 0.9674124778965603\n",
            "Q_table[2,3]_old = 0.6356629646918259\n",
            "Q_table[(2, 3)]_new = 0.6395091461192036\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1892 episode and 11 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,0]_old = 0.0\n",
            "Q_table[(2, 0)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1893 episode and 0 step\n",
            "Delta Q = 0.9732456265248873\n",
            "Q_table[0,1]_old = 0.8559992410945998\n",
            "Q_table[(0, 1)]_new = 0.8436449435100272\n",
            "We are on 0 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1893 episode and 1 step\n",
            "Delta Q = 0.9732456265248873\n",
            "Q_table[7,2]_old = 0.7188209375391671\n",
            "Q_table[(7, 2)]_new = 0.7201844703101377\n",
            "We are on 7 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1893 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1894 episode and 0 step\n",
            "Delta Q = 0.9674124778965603\n",
            "Q_table[0,0]_old = 0.8260182115901308\n",
            "Q_table[(0, 0)]_new = 0.810828868327678\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1894 episode and 1 step\n",
            "Delta Q = 0.9674124778965603\n",
            "Q_table[2,3]_old = 0.6395091461192036\n",
            "Q_table[(2, 3)]_new = 0.6429707094038435\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1894 episode and 2 step\n",
            "Delta Q = 0.9674124778965603\n",
            "Q_table[2,3]_old = 0.6429707094038435\n",
            "Q_table[(2, 3)]_new = 0.6460861163600194\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1894 episode and 3 step\n",
            "Delta Q = 0.9709210754237559\n",
            "Q_table[2,2]_old = 0.6809341201672747\n",
            "Q_table[(2, 2)]_new = 0.6837617835743032\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1894 episode and 4 step\n",
            "Delta Q = 0.9676924165738561\n",
            "Q_table[3,0]_old = 0.663879503861554\n",
            "Q_table[(3, 0)]_new = 0.6651839700492547\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1894 episode and 5 step\n",
            "Delta Q = 0.9676924165738561\n",
            "Q_table[2,3]_old = 0.6460861163600194\n",
            "Q_table[(2, 3)]_new = 0.6491699212978735\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1894 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,0]_old = 0.0\n",
            "Q_table[(2, 0)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1895 episode and 0 step\n",
            "Delta Q = 0.9938987012363476\n",
            "Q_table[0,0]_old = 0.810828868327678\n",
            "Q_table[(0, 0)]_new = 0.8236446827312578\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1895 episode and 1 step\n",
            "Delta Q = 0.9954132620948379\n",
            "Q_table[4,1]_old = 0.9484717296600764\n",
            "Q_table[(4, 1)]_new = 0.9490378187889066\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1895 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,1]_old = 0.0\n",
            "Q_table[(8, 1)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1896 episode and 0 step\n",
            "Delta Q = 0.9954132620948379\n",
            "Q_table[0,1]_old = 0.8436449435100272\n",
            "Q_table[(0, 1)]_new = 0.8546937112538624\n",
            "We are on 0 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1896 episode and 1 step\n",
            "Delta Q = 0.9939547440601018\n",
            "Q_table[8,3]_old = 0.9287391218636454\n",
            "Q_table[(8, 3)]_new = 0.9298199537373826\n",
            "We are on 8 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1896 episode and 2 step\n",
            "Delta Q = 0.9954132620948379\n",
            "Q_table[4,1]_old = 0.9490378187889066\n",
            "Q_table[(4, 1)]_new = 0.9495472990048539\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1896 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,1]_old = 0.0\n",
            "Q_table[(8, 1)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1897 episode and 0 step\n",
            "Delta Q = 0.9732456265248873\n",
            "Q_table[0,1]_old = 0.8546937112538624\n",
            "Q_table[(0, 1)]_new = 0.8424699666533635\n",
            "We are on 0 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1897 episode and 1 step\n",
            "Delta Q = 0.975024415312434\n",
            "Q_table[7,1]_old = 0.7398548133826999\n",
            "Q_table[(7, 1)]_new = 0.7408937473568639\n",
            "We are on 7 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1897 episode and 2 step\n",
            "Delta Q = 0.9733484809883295\n",
            "Q_table[11,3]_old = 0.7062829126493702\n",
            "Q_table[(11, 3)]_new = 0.7090031023727628\n",
            "We are on 11 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1897 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1898 episode and 0 step\n",
            "Delta Q = 0.9676924165738561\n",
            "Q_table[0,0]_old = 0.8236446827312578\n",
            "Q_table[(0, 0)]_new = 0.8089726310319881\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1898 episode and 1 step\n",
            "Delta Q = 0.9709210754237559\n",
            "Q_table[2,2]_old = 0.6837617835743032\n",
            "Q_table[(2, 2)]_new = 0.6863066806406288\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1898 episode and 2 step\n",
            "Delta Q = 0.9709210754237559\n",
            "Q_table[3,3]_old = 0.6958349862771267\n",
            "Q_table[(3, 3)]_new = 0.69717256307317\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1898 episode and 3 step\n",
            "Delta Q = 0.9709210754237559\n",
            "Q_table[3,3]_old = 0.69717256307317\n",
            "Q_table[(3, 3)]_new = 0.698376382189609\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1898 episode and 4 step\n",
            "Delta Q = 0.9733484809883295\n",
            "Q_table[3,1]_old = 0.716374499229858\n",
            "Q_table[(3, 1)]_new = 0.7180855302952016\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1898 episode and 5 step\n",
            "Delta Q = 0.9733484809883295\n",
            "Q_table[7,2]_old = 0.7201844703101377\n",
            "Q_table[(7, 2)]_new = 0.7215145042674533\n",
            "We are on 7 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1898 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1899 episode and 0 step\n",
            "Delta Q = 0.971090467499225\n",
            "Q_table[0,2]_old = 0.09280736532550163\n",
            "Q_table[(0, 2)]_new = 0.15461709629217646\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1899 episode and 1 step\n",
            "Delta Q = 0.971090467499225\n",
            "Q_table[3,2]_old = 0.6984381232006914\n",
            "Q_table[(3, 2)]_new = 0.6996847783798473\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1899 episode and 2 step\n",
            "Delta Q = 0.9733484809883295\n",
            "Q_table[3,1]_old = 0.7180855302952016\n",
            "Q_table[(3, 1)]_new = 0.7196254582540109\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1899 episode and 3 step\n",
            "Delta Q = 0.9712429203671471\n",
            "Q_table[7,3]_old = 0.6835186271881442\n",
            "Q_table[(7, 3)]_new = 0.6864096848364768\n",
            "We are on 7 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1899 episode and 4 step\n",
            "Delta Q = 0.9733484809883295\n",
            "Q_table[3,1]_old = 0.7196254582540109\n",
            "Q_table[(3, 1)]_new = 0.7210113934169393\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1899 episode and 5 step\n",
            "Delta Q = 0.975024415312434\n",
            "Q_table[7,1]_old = 0.7408937473568639\n",
            "Q_table[(7, 1)]_new = 0.7418287879336115\n",
            "We are on 7 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1899 episode and 6 step\n",
            "Delta Q = 0.975024415312434\n",
            "Q_table[11,2]_old = 0.6960952405897173\n",
            "Q_table[(11, 2)]_new = 0.7015101318431796\n",
            "We are on 11 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1899 episode and 7 step\n",
            "Delta Q = 0.9734410500054276\n",
            "Q_table[11,3]_old = 0.7090031023727628\n",
            "Q_table[(11, 3)]_new = 0.711543842140914\n",
            "We are on 11 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1899 episode and 8 step\n",
            "Delta Q = 0.975024415312434\n",
            "Q_table[7,1]_old = 0.7418287879336115\n",
            "Q_table[(7, 1)]_new = 0.7426703244526843\n",
            "We are on 7 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1899 episode and 9 step\n",
            "Delta Q = 0.9\n",
            "Q_table[11,0]_old = 0.0\n",
            "Q_table[(11, 0)]_new = 0.0\n",
            "We are on 11 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1900 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,2]_old = 0.15461709629217646\n",
            "Q_table[(0, 2)]_new = 0.13915538666295882\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1901 episode and 0 step\n",
            "Delta Q = 0.9735243621208157\n",
            "Q_table[0,1]_old = 0.8424699666533635\n",
            "Q_table[(0, 1)]_new = 0.8317473321088429\n",
            "We are on 0 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1901 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1902 episode and 0 step\n",
            "Delta Q = 0.971380127948277\n",
            "Q_table[0,2]_old = 0.13915538666295882\n",
            "Q_table[(0, 2)]_new = 0.19661997594493993\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1902 episode and 1 step\n",
            "Delta Q = 0.9735243621208157\n",
            "Q_table[3,1]_old = 0.7210113934169393\n",
            "Q_table[(3, 1)]_new = 0.7224346161960611\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1902 episode and 2 step\n",
            "Delta Q = 0.9735243621208157\n",
            "Q_table[7,2]_old = 0.7215145042674533\n",
            "Q_table[(7, 2)]_new = 0.7228874159615237\n",
            "We are on 7 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1902 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1903 episode and 0 step\n",
            "Delta Q = 0.9679443613834223\n",
            "Q_table[0,0]_old = 0.8089726310319881\n",
            "Q_table[(0, 0)]_new = 0.7960197293122117\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1903 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,0]_old = 0.0\n",
            "Q_table[(2, 0)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1904 episode and 0 step\n",
            "Delta Q = 0.9679443613834223\n",
            "Q_table[0,0]_old = 0.7960197293122117\n",
            "Q_table[(0, 0)]_new = 0.7843621177644128\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1904 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,0]_old = 0.0\n",
            "Q_table[(2, 0)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1905 episode and 0 step\n",
            "Delta Q = 0.97152102700341\n",
            "Q_table[0,2]_old = 0.19661997594493993\n",
            "Q_table[(0, 2)]_new = 0.24847900535385598\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1905 episode and 1 step\n",
            "Delta Q = 0.9679443613834223\n",
            "Q_table[3,0]_old = 0.6651839700492547\n",
            "Q_table[(3, 0)]_new = 0.6666099344277515\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1905 episode and 2 step\n",
            "Delta Q = 0.9679443613834223\n",
            "Q_table[2,3]_old = 0.6491699212978735\n",
            "Q_table[(2, 3)]_new = 0.6521972905515085\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1905 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,0]_old = 0.0\n",
            "Q_table[(2, 0)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1906 episode and 0 step\n",
            "Delta Q = 0.97152102700341\n",
            "Q_table[0,3]_old = 0.7967695797732608\n",
            "Q_table[(0, 3)]_new = 0.7886136487993447\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1906 episode and 1 step\n",
            "Delta Q = 0.9735243621208157\n",
            "Q_table[3,1]_old = 0.7224346161960611\n",
            "Q_table[(3, 1)]_new = 0.7237155166972707\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1906 episode and 2 step\n",
            "Delta Q = 0.9716478361530299\n",
            "Q_table[7,3]_old = 0.6864096848364768\n",
            "Q_table[(7, 3)]_new = 0.689416552505859\n",
            "We are on 7 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1906 episode and 3 step\n",
            "Delta Q = 0.9679443613834223\n",
            "Q_table[3,0]_old = 0.6666099344277515\n",
            "Q_table[(3, 0)]_new = 0.6678933023683987\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1906 episode and 4 step\n",
            "Delta Q = 0.9716478361530299\n",
            "Q_table[2,2]_old = 0.6863066806406288\n",
            "Q_table[(2, 2)]_new = 0.6893238487295958\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1906 episode and 5 step\n",
            "Delta Q = 0.9735243621208157\n",
            "Q_table[3,1]_old = 0.7237155166972707\n",
            "Q_table[(3, 1)]_new = 0.7248683271483594\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1906 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1907 episode and 0 step\n",
            "Delta Q = 0.9823429858787754\n",
            "Q_table[0,3]_old = 0.7886136487993447\n",
            "Q_table[(0, 3)]_new = 0.7920952697981857\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1907 episode and 1 step\n",
            "Delta Q = 0.9823429858787754\n",
            "Q_table[0,3]_old = 0.7920952697981857\n",
            "Q_table[(0, 3)]_new = 0.7952287286971426\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1907 episode and 2 step\n",
            "Delta Q = 0.9823429858787754\n",
            "Q_table[0,3]_old = 0.7952287286971426\n",
            "Q_table[(0, 3)]_new = 0.7980488417062037\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1907 episode and 3 step\n",
            "Delta Q = 0.9823429858787754\n",
            "Q_table[0,3]_old = 0.7980488417062037\n",
            "Q_table[(0, 3)]_new = 0.8005869434143588\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1907 episode and 4 step\n",
            "Delta Q = 0.9823429858787754\n",
            "Q_table[0,3]_old = 0.8005869434143588\n",
            "Q_table[(0, 3)]_new = 0.8028712349516983\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1907 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,2]_old = 0.24847900535385598\n",
            "Q_table[(0, 2)]_new = 0.22363110481847037\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1908 episode and 0 step\n",
            "Delta Q = 0.9954132620948379\n",
            "Q_table[0,1]_old = 0.8317473321088429\n",
            "Q_table[(0, 1)]_new = 0.8439858609927964\n",
            "We are on 0 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1908 episode and 1 step\n",
            "Delta Q = 0.9940051826014806\n",
            "Q_table[8,3]_old = 0.9298199537373826\n",
            "Q_table[(8, 3)]_new = 0.930843140965125\n",
            "We are on 8 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1908 episode and 2 step\n",
            "Delta Q = 0.9954132620948379\n",
            "Q_table[4,1]_old = 0.9495472990048539\n",
            "Q_table[(4, 1)]_new = 0.9500058311992063\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1908 episode and 3 step\n",
            "Delta Q = 0.9969927196005459\n",
            "Q_table[8,2]_old = 0.9637703241902813\n",
            "Q_table[(8, 2)]_new = 0.9643860113717991\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1908 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[9,3]_old = 0.0\n",
            "Q_table[(9, 3)]_new = 0.0\n",
            "We are on 9 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1909 episode and 0 step\n",
            "Delta Q = 0.96824306102423\n",
            "Q_table[0,0]_old = 0.7843621177644128\n",
            "Q_table[(0, 0)]_new = 0.7741689670122015\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1909 episode and 1 step\n",
            "Delta Q = 0.9717619643876876\n",
            "Q_table[2,2]_old = 0.6893238487295958\n",
            "Q_table[(2, 2)]_new = 0.6921534282443238\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1909 episode and 2 step\n",
            "Delta Q = 0.9717619643876876\n",
            "Q_table[3,3]_old = 0.698376382189609\n",
            "Q_table[(3, 3)]_new = 0.7003007083583357\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1909 episode and 3 step\n",
            "Delta Q = 0.9735243621208157\n",
            "Q_table[3,1]_old = 0.7248683271483594\n",
            "Q_table[(3, 1)]_new = 0.7259058565543391\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1909 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1910 episode and 0 step\n",
            "Delta Q = 0.9718646797988796\n",
            "Q_table[0,3]_old = 0.8028712349516983\n",
            "Q_table[(0, 3)]_new = 0.794448791255408\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1910 episode and 1 step\n",
            "Delta Q = 0.9718646797988796\n",
            "Q_table[3,2]_old = 0.6996847783798473\n",
            "Q_table[(3, 2)]_new = 0.7015809803407421\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1910 episode and 2 step\n",
            "Delta Q = 0.9735243621208157\n",
            "Q_table[3,1]_old = 0.7259058565543391\n",
            "Q_table[(3, 1)]_new = 0.726839633019721\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1910 episode and 3 step\n",
            "Delta Q = 0.9719571236689524\n",
            "Q_table[7,3]_old = 0.689416552505859\n",
            "Q_table[(7, 3)]_new = 0.6924320209242254\n",
            "We are on 7 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1910 episode and 4 step\n",
            "Delta Q = 0.9719571236689524\n",
            "Q_table[3,3]_old = 0.7003007083583357\n",
            "Q_table[(3, 3)]_new = 0.7022277611914545\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1910 episode and 5 step\n",
            "Delta Q = 0.9719571236689524\n",
            "Q_table[3,2]_old = 0.7015809803407421\n",
            "Q_table[(3, 2)]_new = 0.7033800059756202\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1910 episode and 6 step\n",
            "Delta Q = 0.9719571236689524\n",
            "Q_table[3,2]_old = 0.7033800059756202\n",
            "Q_table[(3, 2)]_new = 0.7049991290470106\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1910 episode and 7 step\n",
            "Delta Q = 0.9735243621208157\n",
            "Q_table[3,1]_old = 0.726839633019721\n",
            "Q_table[(3, 1)]_new = 0.7276800318385646\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1910 episode and 8 step\n",
            "Delta Q = 0.975024415312434\n",
            "Q_table[7,1]_old = 0.7426703244526843\n",
            "Q_table[(7, 1)]_new = 0.7434277073198499\n",
            "We are on 7 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1910 episode and 9 step\n",
            "Delta Q = 0.975024415312434\n",
            "Q_table[11,2]_old = 0.7015101318431796\n",
            "Q_table[(11, 2)]_new = 0.7063835339712956\n",
            "We are on 11 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1910 episode and 10 step\n",
            "Delta Q = 0.9735993430246651\n",
            "Q_table[11,3]_old = 0.711543842140914\n",
            "Q_table[(11, 3)]_new = 0.7139888009514878\n",
            "We are on 11 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1910 episode and 11 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1911 episode and 0 step\n",
            "Delta Q = 0.9940505772887215\n",
            "Q_table[0,0]_old = 0.7741689670122015\n",
            "Q_table[(0, 0)]_new = 0.7908026475997029\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1911 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1912 episode and 0 step\n",
            "Delta Q = 0.9720403231520179\n",
            "Q_table[0,3]_old = 0.794448791255408\n",
            "Q_table[(0, 3)]_new = 0.7870442352818852\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1912 episode and 1 step\n",
            "Delta Q = 0.9720403231520179\n",
            "Q_table[3,3]_old = 0.7022277611914545\n",
            "Q_table[(3, 3)]_new = 0.704045308224327\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1912 episode and 2 step\n",
            "Delta Q = 0.9735993430246651\n",
            "Q_table[3,1]_old = 0.7276800318385646\n",
            "Q_table[(3, 1)]_new = 0.7285113716793732\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1912 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1913 episode and 0 step\n",
            "Delta Q = 0.9735993430246651\n",
            "Q_table[0,1]_old = 0.8439858609927964\n",
            "Q_table[(0, 1)]_new = 0.8331866179181818\n",
            "We are on 0 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1913 episode and 1 step\n",
            "Delta Q = 0.975024415312434\n",
            "Q_table[7,1]_old = 0.7434277073198499\n",
            "Q_table[(7, 1)]_new = 0.7441093519002989\n",
            "We are on 7 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1913 episode and 2 step\n",
            "Delta Q = 0.9736668258381296\n",
            "Q_table[11,3]_old = 0.7139888009514878\n",
            "Q_table[(11, 3)]_new = 0.7162567466944686\n",
            "We are on 11 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1913 episode and 3 step\n",
            "Delta Q = 0.972122625796258\n",
            "Q_table[7,3]_old = 0.6924320209242254\n",
            "Q_table[(7, 3)]_new = 0.6953114446280608\n",
            "We are on 7 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1913 episode and 4 step\n",
            "Delta Q = 0.9685231893961881\n",
            "Q_table[3,0]_old = 0.6678933023683987\n",
            "Q_table[(3, 0)]_new = 0.6696271615277469\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1913 episode and 5 step\n",
            "Delta Q = 0.972122625796258\n",
            "Q_table[2,2]_old = 0.6921534282443238\n",
            "Q_table[(2, 2)]_new = 0.6950607112161494\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1913 episode and 6 step\n",
            "Delta Q = 0.972122625796258\n",
            "Q_table[3,2]_old = 0.7049991290470106\n",
            "Q_table[(3, 2)]_new = 0.7066218419385675\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1913 episode and 7 step\n",
            "Delta Q = 0.9736668258381296\n",
            "Q_table[3,1]_old = 0.7285113716793732\n",
            "Q_table[(3, 1)]_new = 0.7293270603495654\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1913 episode and 8 step\n",
            "Delta Q = 0.9736668258381296\n",
            "Q_table[7,2]_old = 0.7228874159615237\n",
            "Q_table[(7, 2)]_new = 0.7242655002035009\n",
            "We are on 7 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1913 episode and 9 step\n",
            "Delta Q = 0.972203378974607\n",
            "Q_table[7,3]_old = 0.6953114446280608\n",
            "Q_table[(7, 3)]_new = 0.6979836791398617\n",
            "We are on 7 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1913 episode and 10 step\n",
            "Delta Q = 0.972203378974607\n",
            "Q_table[3,2]_old = 0.7066218419385675\n",
            "Q_table[(3, 2)]_new = 0.7081630367193177\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1913 episode and 11 step\n",
            "Delta Q = 0.9688110104103989\n",
            "Q_table[3,0]_old = 0.6696271615277469\n",
            "Q_table[(3, 0)]_new = 0.671475455785371\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1913 episode and 12 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,1]_old = 0.0\n",
            "Q_table[(2, 1)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1914 episode and 0 step\n",
            "Delta Q = 0.9954742151258081\n",
            "Q_table[0,1]_old = 0.8331866179181818\n",
            "Q_table[(0, 1)]_new = 0.8453421712521718\n",
            "We are on 0 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1914 episode and 1 step\n",
            "Delta Q = 0.9969927196005459\n",
            "Q_table[8,2]_old = 0.9643860113717991\n",
            "Q_table[(8, 2)]_new = 0.9649401298351651\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1914 episode and 2 step\n",
            "Delta Q = 0.9955290728536814\n",
            "Q_table[9,0]_old = 0.896167088632644\n",
            "Q_table[(9, 0)]_new = 0.9020794526230611\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1914 episode and 3 step\n",
            "Delta Q = 0.9940505772887215\n",
            "Q_table[8,3]_old = 0.930843140965125\n",
            "Q_table[(8, 3)]_new = 0.9318094041573339\n",
            "We are on 8 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1914 episode and 4 step\n",
            "Delta Q = 0.9955290728536814\n",
            "Q_table[4,1]_old = 0.9500058311992063\n",
            "Q_table[(4, 1)]_new = 0.9505343209329671\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1914 episode and 5 step\n",
            "Delta Q = 0.9955290728536814\n",
            "Q_table[8,0]_old = 0.9459988018994231\n",
            "Q_table[(8, 0)]_new = 0.9469279945631621\n",
            "We are on 8 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1914 episode and 6 step\n",
            "Delta Q = 0.9955290728536814\n",
            "Q_table[8,0]_old = 0.9469279945631621\n",
            "Q_table[(8, 0)]_new = 0.9477642679605274\n",
            "We are on 8 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1914 episode and 7 step\n",
            "Delta Q = 0.9969927196005459\n",
            "Q_table[8,2]_old = 0.9649401298351651\n",
            "Q_table[(8, 2)]_new = 0.9654388364521945\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1914 episode and 8 step\n",
            "Delta Q = 1.0\n",
            "Q_table[9,1]_old = 0.9797244404095546\n",
            "Q_table[(9, 1)]_new = 0.9817519963685992\n",
            "We are on 9 state\n",
            "And now we are on 13 state\n",
            "We get 1.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1915 episode and 0 step\n",
            "Delta Q = 0.972203378974607\n",
            "Q_table[0,3]_old = 0.7870442352818852\n",
            "Q_table[(0, 3)]_new = 0.7805431907283036\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1915 episode and 1 step\n",
            "Delta Q = 0.972203378974607\n",
            "Q_table[3,3]_old = 0.704045308224327\n",
            "Q_table[(3, 3)]_new = 0.7058441563765012\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1915 episode and 2 step\n",
            "Delta Q = 0.972203378974607\n",
            "Q_table[3,3]_old = 0.7058441563765012\n",
            "Q_table[(3, 3)]_new = 0.7074631197134581\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1915 episode and 3 step\n",
            "Delta Q = 0.9736668258381296\n",
            "Q_table[3,1]_old = 0.7293270603495654\n",
            "Q_table[(3, 1)]_new = 0.7300611801527385\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1915 episode and 4 step\n",
            "Delta Q = 0.975024415312434\n",
            "Q_table[7,1]_old = 0.7441093519002989\n",
            "Q_table[(7, 1)]_new = 0.7447228320227031\n",
            "We are on 7 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1915 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[11,0]_old = 0.0\n",
            "Q_table[(11, 0)]_new = 0.0\n",
            "We are on 11 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1916 episode and 0 step\n",
            "Delta Q = 0.9737275603702477\n",
            "Q_table[0,1]_old = 0.8453421712521718\n",
            "Q_table[(0, 1)]_new = 0.8345355144972023\n",
            "We are on 0 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1916 episode and 1 step\n",
            "Delta Q = 0.9722760568351211\n",
            "Q_table[7,3]_old = 0.6979836791398617\n",
            "Q_table[(7, 3)]_new = 0.7004613680609966\n",
            "We are on 7 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1916 episode and 2 step\n",
            "Delta Q = 0.9722760568351211\n",
            "Q_table[3,2]_old = 0.7081630367193177\n",
            "Q_table[(3, 2)]_new = 0.709622789882507\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1916 episode and 3 step\n",
            "Delta Q = 0.9722760568351211\n",
            "Q_table[3,2]_old = 0.709622789882507\n",
            "Q_table[(3, 2)]_new = 0.7109365677293774\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1916 episode and 4 step\n",
            "Delta Q = 0.9737275603702477\n",
            "Q_table[3,1]_old = 0.7300611801527385\n",
            "Q_table[(3, 1)]_new = 0.7307826225077123\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1916 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1917 episode and 0 step\n",
            "Delta Q = 0.9723474796282635\n",
            "Q_table[0,2]_old = 0.22363110481847037\n",
            "Q_table[(0, 2)]_new = 0.2736154739648869\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1917 episode and 1 step\n",
            "Delta Q = 0.9723474796282635\n",
            "Q_table[3,2]_old = 0.7109365677293774\n",
            "Q_table[(3, 2)]_new = 0.7121903905847031\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1917 episode and 2 step\n",
            "Delta Q = 0.9723474796282635\n",
            "Q_table[3,2]_old = 0.7121903905847031\n",
            "Q_table[(3, 2)]_new = 0.7133188311544963\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1917 episode and 3 step\n",
            "Delta Q = 0.9688110104103989\n",
            "Q_table[3,0]_old = 0.671475455785371\n",
            "Q_table[(3, 0)]_new = 0.6731389206172328\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1917 episode and 4 step\n",
            "Delta Q = 0.9723474796282635\n",
            "Q_table[2,2]_old = 0.6950607112161494\n",
            "Q_table[(2, 2)]_new = 0.697902119722798\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1917 episode and 5 step\n",
            "Delta Q = 0.969092309852557\n",
            "Q_table[3,0]_old = 0.6731389206172328\n",
            "Q_table[(3, 0)]_new = 0.6749173384080666\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1917 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,0]_old = 0.0\n",
            "Q_table[(2, 0)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1918 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,2]_old = 0.2736154739648869\n",
            "Q_table[(0, 2)]_new = 0.2462539265683982\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1919 episode and 0 step\n",
            "Delta Q = 0.9737275603702477\n",
            "Q_table[0,1]_old = 0.8345355144972023\n",
            "Q_table[(0, 1)]_new = 0.8248095234177297\n",
            "We are on 0 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1919 episode and 1 step\n",
            "Delta Q = 0.9723474796282635\n",
            "Q_table[7,3]_old = 0.7004613680609966\n",
            "Q_table[(7, 3)]_new = 0.7027627108831604\n",
            "We are on 7 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1919 episode and 2 step\n",
            "Delta Q = 0.969092309852557\n",
            "Q_table[3,0]_old = 0.6749173384080666\n",
            "Q_table[(3, 0)]_new = 0.6765179144198169\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1919 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,0]_old = 0.0\n",
            "Q_table[(2, 0)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1920 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,2]_old = 0.2462539265683982\n",
            "Q_table[(0, 2)]_new = 0.22162853391155837\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1921 episode and 0 step\n",
            "Delta Q = 0.9723474796282635\n",
            "Q_table[0,3]_old = 0.7805431907283036\n",
            "Q_table[(0, 3)]_new = 0.7748363512837367\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1921 episode and 1 step\n",
            "Delta Q = 0.9723474796282635\n",
            "Q_table[3,3]_old = 0.7074631197134581\n",
            "Q_table[(3, 3)]_new = 0.7090642873703757\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1921 episode and 2 step\n",
            "Delta Q = 0.9723474796282635\n",
            "Q_table[3,2]_old = 0.7133188311544963\n",
            "Q_table[(3, 2)]_new = 0.7143344276673103\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1921 episode and 3 step\n",
            "Delta Q = 0.969092309852557\n",
            "Q_table[3,0]_old = 0.6765179144198169\n",
            "Q_table[(3, 0)]_new = 0.6779584328303923\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1921 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,0]_old = 0.0\n",
            "Q_table[(2, 0)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1922 episode and 0 step\n",
            "Delta Q = 0.9816561428183552\n",
            "Q_table[0,3]_old = 0.7748363512837367\n",
            "Q_table[(0, 3)]_new = 0.7790088589737183\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1922 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,2]_old = 0.22162853391155837\n",
            "Q_table[(0, 2)]_new = 0.19946568052040253\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1923 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,2]_old = 0.19946568052040253\n",
            "Q_table[(0, 2)]_new = 0.17951911246836227\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1924 episode and 0 step\n",
            "Delta Q = 0.9816561428183552\n",
            "Q_table[0,3]_old = 0.7790088589737183\n",
            "Q_table[(0, 3)]_new = 0.7827641158947017\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1924 episode and 1 step\n",
            "Delta Q = 0.9941028977723638\n",
            "Q_table[0,1]_old = 0.8248095234177297\n",
            "Q_table[(0, 1)]_new = 0.8364314688483205\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1924 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1925 episode and 0 step\n",
            "Delta Q = 0.9941028977723638\n",
            "Q_table[0,0]_old = 0.7908026475997029\n",
            "Q_table[(0, 0)]_new = 0.8058252806120962\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1925 episode and 1 step\n",
            "Delta Q = 0.9941028977723638\n",
            "Q_table[4,0]_old = 0.9323093895294026\n",
            "Q_table[(4, 0)]_new = 0.933181348348826\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1925 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1926 episode and 0 step\n",
            "Delta Q = 0.9955784448087672\n",
            "Q_table[0,1]_old = 0.8364314688483205\n",
            "Q_table[(0, 1)]_new = 0.8483667667722559\n",
            "We are on 0 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1926 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,1]_old = 0.0\n",
            "Q_table[(8, 1)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1927 episode and 0 step\n",
            "Delta Q = 0.9723474796282635\n",
            "Q_table[0,2]_old = 0.17951911246836227\n",
            "Q_table[(0, 2)]_new = 0.23391468084978956\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1927 episode and 1 step\n",
            "Delta Q = 0.9737275603702477\n",
            "Q_table[3,1]_old = 0.7307826225077123\n",
            "Q_table[(3, 1)]_new = 0.7314319206271888\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1927 episode and 2 step\n",
            "Delta Q = 0.9737275603702477\n",
            "Q_table[7,2]_old = 0.7242655002035009\n",
            "Q_table[(7, 2)]_new = 0.7255665105533985\n",
            "We are on 7 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1927 episode and 3 step\n",
            "Delta Q = 0.975024415312434\n",
            "Q_table[7,1]_old = 0.7447228320227031\n",
            "Q_table[(7, 1)]_new = 0.7452749641328668\n",
            "We are on 7 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1927 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[11,0]_old = 0.0\n",
            "Q_table[(11, 0)]_new = 0.0\n",
            "We are on 11 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1928 episode and 0 step\n",
            "Delta Q = 0.9839883099104534\n",
            "Q_table[0,3]_old = 0.7827641158947017\n",
            "Q_table[(0, 3)]_new = 0.7884760142156849\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1928 episode and 1 step\n",
            "Delta Q = 0.9839883099104534\n",
            "Q_table[0,0]_old = 0.8058252806120962\n",
            "Q_table[(0, 0)]_new = 0.80923106246134\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1928 episode and 2 step\n",
            "Delta Q = 0.9839883099104534\n",
            "Q_table[0,3]_old = 0.7884760142156849\n",
            "Q_table[(0, 3)]_new = 0.7936167227045698\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1928 episode and 3 step\n",
            "Delta Q = 0.9839883099104534\n",
            "Q_table[0,3]_old = 0.7936167227045698\n",
            "Q_table[(0, 3)]_new = 0.7982433603445662\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1928 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,2]_old = 0.23391468084978956\n",
            "Q_table[(0, 2)]_new = 0.21052321276481062\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1929 episode and 0 step\n",
            "Delta Q = 0.9941028977723638\n",
            "Q_table[0,0]_old = 0.80923106246134\n",
            "Q_table[(0, 0)]_new = 0.8224108539875699\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1929 episode and 1 step\n",
            "Delta Q = 0.9941028977723638\n",
            "Q_table[4,0]_old = 0.933181348348826\n",
            "Q_table[(4, 0)]_new = 0.9339661112863071\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1929 episode and 2 step\n",
            "Delta Q = 0.9941028977723638\n",
            "Q_table[4,0]_old = 0.9339661112863071\n",
            "Q_table[(4, 0)]_new = 0.9346723979300402\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1929 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1930 episode and 0 step\n",
            "Delta Q = 0.9724117601420917\n",
            "Q_table[0,3]_old = 0.7982433603445662\n",
            "Q_table[(0, 3)]_new = 0.7908307844522013\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1930 episode and 1 step\n",
            "Delta Q = 0.9737822214491538\n",
            "Q_table[3,1]_old = 0.7314319206271888\n",
            "Q_table[(3, 1)]_new = 0.7320709500136237\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1930 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1931 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,2]_old = 0.21052321276481062\n",
            "Q_table[(0, 2)]_new = 0.18947089148832957\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1932 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,2]_old = 0.18947089148832957\n",
            "Q_table[(0, 2)]_new = 0.17052380233949663\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1933 episode and 0 step\n",
            "Delta Q = 0.9941028977723638\n",
            "Q_table[0,0]_old = 0.8224108539875699\n",
            "Q_table[(0, 0)]_new = 0.8342726663611766\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1933 episode and 1 step\n",
            "Delta Q = 0.9839883099104534\n",
            "Q_table[4,3]_old = 0.85391905360673\n",
            "Q_table[(4, 3)]_new = 0.8525154581565104\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1933 episode and 2 step\n",
            "Delta Q = 0.9839883099104534\n",
            "Q_table[0,3]_old = 0.7908307844522013\n",
            "Q_table[(0, 3)]_new = 0.7957360159174346\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1933 episode and 3 step\n",
            "Delta Q = 0.9839883099104534\n",
            "Q_table[0,3]_old = 0.7957360159174346\n",
            "Q_table[(0, 3)]_new = 0.8001507242361445\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1933 episode and 4 step\n",
            "Delta Q = 0.9839883099104534\n",
            "Q_table[0,0]_old = 0.8342726663611766\n",
            "Q_table[(0, 0)]_new = 0.8348337096355123\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1933 episode and 5 step\n",
            "Delta Q = 0.9941028977723638\n",
            "Q_table[0,1]_old = 0.8483667667722559\n",
            "Q_table[(0, 1)]_new = 0.8576329878673941\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1933 episode and 6 step\n",
            "Delta Q = 0.9849056657988721\n",
            "Q_table[4,3]_old = 0.8525154581565104\n",
            "Q_table[(4, 3)]_new = 0.8521695781397315\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1933 episode and 7 step\n",
            "Delta Q = 0.9849056657988721\n",
            "Q_table[0,0]_old = 0.8348337096355123\n",
            "Q_table[(0, 0)]_new = 0.8362560044708331\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1933 episode and 8 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,2]_old = 0.17052380233949663\n",
            "Q_table[(0, 2)]_new = 0.15347142210554696\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1934 episode and 0 step\n",
            "Delta Q = 0.9849056657988721\n",
            "Q_table[0,3]_old = 0.8001507242361445\n",
            "Q_table[(0, 3)]_new = 0.8050413176114022\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1934 episode and 1 step\n",
            "Delta Q = 0.9849056657988721\n",
            "Q_table[0,3]_old = 0.8050413176114022\n",
            "Q_table[(0, 3)]_new = 0.809442851649134\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1934 episode and 2 step\n",
            "Delta Q = 0.9941028977723638\n",
            "Q_table[0,1]_old = 0.8576329878673941\n",
            "Q_table[(0, 1)]_new = 0.8659725868530184\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1934 episode and 3 step\n",
            "Delta Q = 0.9941028977723638\n",
            "Q_table[4,0]_old = 0.9346723979300402\n",
            "Q_table[(4, 0)]_new = 0.9353080559094\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1934 episode and 4 step\n",
            "Delta Q = 0.9857312860984488\n",
            "Q_table[4,3]_old = 0.8521695781397315\n",
            "Q_table[(4, 3)]_new = 0.8526839064242072\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1934 episode and 5 step\n",
            "Delta Q = 0.9941028977723638\n",
            "Q_table[0,1]_old = 0.8659725868530184\n",
            "Q_table[(0, 1)]_new = 0.8734782259400804\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1934 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1935 episode and 0 step\n",
            "Delta Q = 0.9955784448087672\n",
            "Q_table[0,1]_old = 0.8734782259400804\n",
            "Q_table[(0, 1)]_new = 0.8817088481548396\n",
            "We are on 0 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1935 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,1]_old = 0.0\n",
            "Q_table[(8, 1)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1936 episode and 0 step\n",
            "Delta Q = 0.9941028977723638\n",
            "Q_table[0,0]_old = 0.8362560044708331\n",
            "Q_table[(0, 0)]_new = 0.8467333017961136\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1936 episode and 1 step\n",
            "Delta Q = 0.9955784448087672\n",
            "Q_table[4,1]_old = 0.9505343209329671\n",
            "Q_table[(4, 1)]_new = 0.9510593336484376\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1936 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,1]_old = 0.0\n",
            "Q_table[(8, 1)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1937 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,2]_old = 0.15347142210554696\n",
            "Q_table[(0, 2)]_new = 0.13812427989499226\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1938 episode and 0 step\n",
            "Delta Q = 0.9941548740311954\n",
            "Q_table[0,0]_old = 0.8467333017961136\n",
            "Q_table[(0, 0)]_new = 0.8562148456476977\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1938 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1939 episode and 0 step\n",
            "Delta Q = 0.969092309852557\n",
            "Q_table[0,0]_old = 0.8562148456476977\n",
            "Q_table[(0, 0)]_new = 0.839685670935485\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1939 episode and 1 step\n",
            "Delta Q = 0.969092309852557\n",
            "Q_table[2,3]_old = 0.6521972905515085\n",
            "Q_table[(2, 3)]_new = 0.6560698713489147\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1939 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,0]_old = 0.0\n",
            "Q_table[(2, 0)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1940 episode and 0 step\n",
            "Delta Q = 0.9737822214491538\n",
            "Q_table[0,1]_old = 0.8817088481548396\n",
            "Q_table[(0, 1)]_new = 0.8673201847885095\n",
            "We are on 0 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1940 episode and 1 step\n",
            "Delta Q = 0.975024415312434\n",
            "Q_table[7,1]_old = 0.7452749641328668\n",
            "Q_table[(7, 1)]_new = 0.745771883032014\n",
            "We are on 7 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1940 episode and 2 step\n",
            "Delta Q = 0.9793046731540052\n",
            "Q_table[11,1]_old = 0.757822376893272\n",
            "Q_table[(11, 1)]_new = 0.7613448123579499\n",
            "We are on 11 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1940 episode and 3 step\n",
            "Delta Q = 0.975373136423437\n",
            "Q_table[15,3]_old = 0.6875887789731251\n",
            "Q_table[(15, 3)]_new = 0.6942030374992496\n",
            "We are on 15 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1940 episode and 4 step\n",
            "Delta Q = 0.9738314164201695\n",
            "Q_table[11,3]_old = 0.7162567466944686\n",
            "Q_table[(11, 3)]_new = 0.7184624884451912\n",
            "We are on 11 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1940 episode and 5 step\n",
            "Delta Q = 0.9724750240513488\n",
            "Q_table[7,3]_old = 0.7027627108831604\n",
            "Q_table[(7, 3)]_new = 0.7049614638461932\n",
            "We are on 7 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1940 episode and 6 step\n",
            "Delta Q = 0.9724750240513488\n",
            "Q_table[3,2]_old = 0.7143344276673103\n",
            "Q_table[(3, 2)]_new = 0.715376008951928\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1940 episode and 7 step\n",
            "Delta Q = 0.9738314164201695\n",
            "Q_table[3,1]_old = 0.7320709500136237\n",
            "Q_table[(3, 1)]_new = 0.7326952714324307\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1940 episode and 8 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1941 episode and 0 step\n",
            "Delta Q = 0.9738314164201695\n",
            "Q_table[0,1]_old = 0.8673201847885095\n",
            "Q_table[(0, 1)]_new = 0.854419582729828\n",
            "We are on 0 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1941 episode and 1 step\n",
            "Delta Q = 0.9725368318718106\n",
            "Q_table[7,3]_old = 0.7049614638461932\n",
            "Q_table[(7, 3)]_new = 0.7070021493333845\n",
            "We are on 7 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1941 episode and 2 step\n",
            "Delta Q = 0.9725368318718106\n",
            "Q_table[3,2]_old = 0.715376008951928\n",
            "Q_table[(3, 2)]_new = 0.7163752399285459\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1941 episode and 3 step\n",
            "Delta Q = 0.9738314164201695\n",
            "Q_table[3,1]_old = 0.7326952714324307\n",
            "Q_table[(3, 1)]_new = 0.7332571607093571\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1941 episode and 4 step\n",
            "Delta Q = 0.975373136423437\n",
            "Q_table[7,1]_old = 0.745771883032014\n",
            "Q_table[(7, 1)]_new = 0.7465678311522497\n",
            "We are on 7 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1941 episode and 5 step\n",
            "Delta Q = 0.9793046731540052\n",
            "Q_table[11,1]_old = 0.7613448123579499\n",
            "Q_table[(11, 1)]_new = 0.76451500427616\n",
            "We are on 11 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1941 episode and 6 step\n",
            "Delta Q = 0.9793046731540052\n",
            "Q_table[15,1]_old = 0.7063431883950061\n",
            "Q_table[(15, 1)]_new = 0.7150135427095107\n",
            "We are on 15 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1941 episode and 7 step\n",
            "Delta Q = 0.9869639111955337\n",
            "Q_table[15,0]_old = 0.8010573045859108\n",
            "Q_table[(15, 0)]_new = 0.8079154853228534\n",
            "We are on 15 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1941 episode and 8 step\n",
            "Delta Q = 0.9869639111955337\n",
            "Q_table[14,1]_old = 0.590171052468135\n",
            "Q_table[(14, 1)]_new = 0.6181178584168552\n",
            "We are on 14 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1941 episode and 9 step\n",
            "Delta Q = 0.9799836330469625\n",
            "Q_table[14,2]_old = 0.5882623891785126\n",
            "Q_table[(14, 2)]_new = 0.6094197833076238\n",
            "We are on 14 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1941 episode and 10 step\n",
            "Delta Q = 0.9869639111955337\n",
            "Q_table[15,0]_old = 0.8079154853228534\n",
            "Q_table[(15, 0)]_new = 0.8140878479861018\n",
            "We are on 15 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1941 episode and 11 step\n",
            "Delta Q = 0.9805946969506241\n",
            "Q_table[14,2]_old = 0.6094197833076238\n",
            "Q_table[(14, 2)]_new = 0.6290725019274855\n",
            "We are on 14 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1941 episode and 12 step\n",
            "Delta Q = 0.9805946969506241\n",
            "Q_table[15,1]_old = 0.7150135427095107\n",
            "Q_table[(15, 1)]_new = 0.7241068853891837\n",
            "We are on 15 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1941 episode and 13 step\n",
            "Delta Q = 0.9805946969506241\n",
            "Q_table[15,2]_old = 0.7089582791966652\n",
            "Q_table[(15, 2)]_new = 0.7186571482276227\n",
            "We are on 15 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1941 episode and 14 step\n",
            "Delta Q = 0.9756869854233399\n",
            "Q_table[15,3]_old = 0.6942030374992496\n",
            "Q_table[(15, 3)]_new = 0.7004697191726645\n",
            "We are on 15 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1941 episode and 15 step\n",
            "Delta Q = 0.9805946969506241\n",
            "Q_table[11,1]_old = 0.76451500427616\n",
            "Q_table[(11, 1)]_new = 0.7686582007991681\n",
            "We are on 11 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1941 episode and 16 step\n",
            "Delta Q = 0.9805946969506241\n",
            "Q_table[15,2]_old = 0.7186571482276227\n",
            "Q_table[(15, 2)]_new = 0.7273861303554845\n",
            "We are on 15 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1941 episode and 17 step\n",
            "Delta Q = 0.9805946969506241\n",
            "Q_table[15,2]_old = 0.7273861303554845\n",
            "Q_table[(15, 2)]_new = 0.7352422142705601\n",
            "We are on 15 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1941 episode and 18 step\n",
            "Delta Q = 0.9760971618791177\n",
            "Q_table[15,3]_old = 0.7004697191726645\n",
            "Q_table[(15, 3)]_new = 0.7065199091345158\n",
            "We are on 15 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1941 episode and 19 step\n",
            "Delta Q = 0.9739102152840727\n",
            "Q_table[11,3]_old = 0.7184624884451912\n",
            "Q_table[(11, 3)]_new = 0.7205264548847449\n",
            "We are on 11 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1941 episode and 20 step\n",
            "Delta Q = 0.9739102152840727\n",
            "Q_table[7,2]_old = 0.7255665105533985\n",
            "Q_table[(7, 2)]_new = 0.7269200747821314\n",
            "We are on 7 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1941 episode and 21 step\n",
            "Delta Q = 0.9725924589102264\n",
            "Q_table[7,3]_old = 0.7070021493333845\n",
            "Q_table[(7, 3)]_new = 0.7088943933102724\n",
            "We are on 7 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1941 episode and 22 step\n",
            "Delta Q = 0.9725924589102264\n",
            "Q_table[3,3]_old = 0.7090642873703757\n",
            "Q_table[(3, 3)]_new = 0.7107503175435645\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1941 episode and 23 step\n",
            "Delta Q = 0.9739102152840727\n",
            "Q_table[3,1]_old = 0.7332571607093571\n",
            "Q_table[(3, 1)]_new = 0.7338416599224941\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1941 episode and 24 step\n",
            "Delta Q = 0.9760971618791177\n",
            "Q_table[7,1]_old = 0.7465678311522497\n",
            "Q_table[(7, 1)]_new = 0.7480082099161424\n",
            "We are on 7 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1941 episode and 25 step\n",
            "Delta Q = 0.9\n",
            "Q_table[11,0]_old = 0.0\n",
            "Q_table[(11, 0)]_new = 0.0\n",
            "We are on 11 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1942 episode and 0 step\n",
            "Delta Q = 0.9740528127816981\n",
            "Q_table[0,1]_old = 0.854419582729828\n",
            "Q_table[(0, 1)]_new = 0.8430304372385433\n",
            "We are on 0 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1942 episode and 1 step\n",
            "Delta Q = 0.9760971618791177\n",
            "Q_table[7,1]_old = 0.7480082099161424\n",
            "Q_table[(7, 1)]_new = 0.7493045508036458\n",
            "We are on 7 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1942 episode and 2 step\n",
            "Delta Q = 0.974181150529561\n",
            "Q_table[11,3]_old = 0.7205264548847449\n",
            "Q_table[(11, 3)]_new = 0.7226549599258314\n",
            "We are on 11 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1942 episode and 3 step\n",
            "Delta Q = 0.9760971618791177\n",
            "Q_table[7,1]_old = 0.7493045508036458\n",
            "Q_table[(7, 1)]_new = 0.7504712576023989\n",
            "We are on 7 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1942 episode and 4 step\n",
            "Delta Q = 0.9760971618791177\n",
            "Q_table[11,2]_old = 0.7063835339712956\n",
            "Q_table[(11, 2)]_new = 0.7118423424532837\n",
            "We are on 11 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1942 episode and 5 step\n",
            "Delta Q = 0.9805946969506241\n",
            "Q_table[11,1]_old = 0.7686582007991681\n",
            "Q_table[(11, 1)]_new = 0.7723870776698754\n",
            "We are on 11 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1942 episode and 6 step\n",
            "Delta Q = 0.9805946969506241\n",
            "Q_table[15,2]_old = 0.7352422142705601\n",
            "Q_table[(15, 2)]_new = 0.7423126897941282\n",
            "We are on 15 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1942 episode and 7 step\n",
            "Delta Q = 0.9805946969506241\n",
            "Q_table[15,1]_old = 0.7241068853891837\n",
            "Q_table[(15, 1)]_new = 0.7322908938008894\n",
            "We are on 15 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1942 episode and 8 step\n",
            "Delta Q = 0.9764663206893177\n",
            "Q_table[15,3]_old = 0.7065199091345158\n",
            "Q_table[(15, 3)]_new = 0.712334238910382\n",
            "We are on 15 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1942 episode and 9 step\n",
            "Delta Q = 0.9764663206893177\n",
            "Q_table[11,2]_old = 0.7118423424532837\n",
            "Q_table[(11, 2)]_new = 0.717124428897273\n",
            "We are on 11 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1942 episode and 10 step\n",
            "Delta Q = 0.9742966545026375\n",
            "Q_table[11,3]_old = 0.7226549599258314\n",
            "Q_table[(11, 3)]_new = 0.7246861184358857\n",
            "We are on 11 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1942 episode and 11 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1943 episode and 0 step\n",
            "Delta Q = 0.9726503243323269\n",
            "Q_table[0,3]_old = 0.809442851649134\n",
            "Q_table[(0, 3)]_new = 0.8011488908165475\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1943 episode and 1 step\n",
            "Delta Q = 0.9726503243323269\n",
            "Q_table[3,3]_old = 0.7107503175435645\n",
            "Q_table[(3, 3)]_new = 0.712325610121535\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1943 episode and 2 step\n",
            "Delta Q = 0.9726503243323269\n",
            "Q_table[3,3]_old = 0.712325610121535\n",
            "Q_table[(3, 3)]_new = 0.7137433734417084\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1943 episode and 3 step\n",
            "Delta Q = 0.9726503243323269\n",
            "Q_table[3,3]_old = 0.7137433734417084\n",
            "Q_table[(3, 3)]_new = 0.7150193604298644\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1943 episode and 4 step\n",
            "Delta Q = 0.969092309852557\n",
            "Q_table[3,0]_old = 0.6779584328303923\n",
            "Q_table[(3, 0)]_new = 0.67925489939991\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1943 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,1]_old = 0.0\n",
            "Q_table[(2, 1)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1944 episode and 0 step\n",
            "Delta Q = 0.9955784448087672\n",
            "Q_table[0,1]_old = 0.8430304372385433\n",
            "Q_table[(0, 1)]_new = 0.8543058383234563\n",
            "We are on 0 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1944 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,1]_old = 0.0\n",
            "Q_table[(8, 1)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1945 episode and 0 step\n",
            "Delta Q = 0.9726503243323269\n",
            "Q_table[0,2]_old = 0.13812427989499226\n",
            "Q_table[(0, 2)]_new = 0.19696217623781997\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1945 episode and 1 step\n",
            "Delta Q = 0.969092309852557\n",
            "Q_table[3,0]_old = 0.67925489939991\n",
            "Q_table[(3, 0)]_new = 0.680421719312476\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1945 episode and 2 step\n",
            "Delta Q = 0.9726503243323269\n",
            "Q_table[2,2]_old = 0.697902119722798\n",
            "Q_table[(2, 2)]_new = 0.7007622320828452\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1945 episode and 3 step\n",
            "Delta Q = 0.9726503243323269\n",
            "Q_table[3,2]_old = 0.7163752399285459\n",
            "Q_table[(3, 2)]_new = 0.7173880402680182\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1945 episode and 4 step\n",
            "Delta Q = 0.9726503243323269\n",
            "Q_table[3,3]_old = 0.7150193604298644\n",
            "Q_table[(3, 3)]_new = 0.7161677487192049\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1945 episode and 5 step\n",
            "Delta Q = 0.9693754609762018\n",
            "Q_table[3,0]_old = 0.680421719312476\n",
            "Q_table[(3, 0)]_new = 0.68175500835743\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1945 episode and 6 step\n",
            "Delta Q = 0.9726503243323269\n",
            "Q_table[2,2]_old = 0.7007622320828452\n",
            "Q_table[(2, 2)]_new = 0.7033363332068875\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1945 episode and 7 step\n",
            "Delta Q = 0.9742966545026375\n",
            "Q_table[3,1]_old = 0.7338416599224941\n",
            "Q_table[(3, 1)]_new = 0.7347541484328821\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1945 episode and 8 step\n",
            "Delta Q = 0.9742966545026375\n",
            "Q_table[7,2]_old = 0.7269200747821314\n",
            "Q_table[(7, 2)]_new = 0.7285247218065557\n",
            "We are on 7 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1945 episode and 9 step\n",
            "Delta Q = 0.9742966545026375\n",
            "Q_table[7,2]_old = 0.7285247218065557\n",
            "Q_table[(7, 2)]_new = 0.7299689041285375\n",
            "We are on 7 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1945 episode and 10 step\n",
            "Delta Q = 0.9727406606948553\n",
            "Q_table[7,3]_old = 0.7088943933102724\n",
            "Q_table[(7, 3)]_new = 0.7107456146741005\n",
            "We are on 7 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1945 episode and 11 step\n",
            "Delta Q = 0.9696302969874819\n",
            "Q_table[3,0]_old = 0.68175500835743\n",
            "Q_table[(3, 0)]_new = 0.6832098045091689\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1945 episode and 12 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,1]_old = 0.0\n",
            "Q_table[(2, 1)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1946 episode and 0 step\n",
            "Delta Q = 0.9727406606948553\n",
            "Q_table[0,3]_old = 0.8011488908165475\n",
            "Q_table[(0, 3)]_new = 0.793774662429748\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1946 episode and 1 step\n",
            "Delta Q = 0.9727406606948553\n",
            "Q_table[3,2]_old = 0.7173880402680182\n",
            "Q_table[(3, 2)]_new = 0.7183898969360717\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1946 episode and 2 step\n",
            "Delta Q = 0.9696302969874819\n",
            "Q_table[3,0]_old = 0.6832098045091689\n",
            "Q_table[(3, 0)]_new = 0.684519121045734\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1946 episode and 3 step\n",
            "Delta Q = 0.9727406606948553\n",
            "Q_table[2,2]_old = 0.7033363332068875\n",
            "Q_table[(2, 2)]_new = 0.705743360581054\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1946 episode and 4 step\n",
            "Delta Q = 0.9727406606948553\n",
            "Q_table[3,2]_old = 0.7183898969360717\n",
            "Q_table[(3, 2)]_new = 0.7192915679373199\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1946 episode and 5 step\n",
            "Delta Q = 0.9698685926975243\n",
            "Q_table[3,0]_old = 0.684519121045734\n",
            "Q_table[(3, 0)]_new = 0.685935801638685\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1946 episode and 6 step\n",
            "Delta Q = 0.9698685926975243\n",
            "Q_table[2,3]_old = 0.6560698713489147\n",
            "Q_table[(2, 3)]_new = 0.6603314769115476\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1946 episode and 7 step\n",
            "Delta Q = 0.9727406606948553\n",
            "Q_table[2,2]_old = 0.705743360581054\n",
            "Q_table[(2, 2)]_new = 0.707909685217804\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1946 episode and 8 step\n",
            "Delta Q = 0.9742966545026375\n",
            "Q_table[3,1]_old = 0.7347541484328821\n",
            "Q_table[(3, 1)]_new = 0.7355753880922313\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1946 episode and 9 step\n",
            "Delta Q = 0.9742966545026375\n",
            "Q_table[7,2]_old = 0.7299689041285375\n",
            "Q_table[(7, 2)]_new = 0.7312686682183213\n",
            "We are on 7 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1946 episode and 10 step\n",
            "Delta Q = 0.9728219634211309\n",
            "Q_table[7,3]_old = 0.7107456146741005\n",
            "Q_table[(7, 3)]_new = 0.7124930166278214\n",
            "We are on 7 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1946 episode and 11 step\n",
            "Delta Q = 0.9728219634211309\n",
            "Q_table[3,2]_old = 0.7192915679373199\n",
            "Q_table[(3, 2)]_new = 0.7201843745647187\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1946 episode and 12 step\n",
            "Delta Q = 0.9728219634211309\n",
            "Q_table[3,3]_old = 0.7161677487192049\n",
            "Q_table[(3, 3)]_new = 0.7173729372684153\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1946 episode and 13 step\n",
            "Delta Q = 0.9742966545026375\n",
            "Q_table[3,1]_old = 0.7355753880922313\n",
            "Q_table[(3, 1)]_new = 0.7363145037856457\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1946 episode and 14 step\n",
            "Delta Q = 0.9742966545026375\n",
            "Q_table[7,2]_old = 0.7312686682183213\n",
            "Q_table[(7, 2)]_new = 0.7324384558991266\n",
            "We are on 7 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1946 episode and 15 step\n",
            "Delta Q = 0.9742966545026375\n",
            "Q_table[7,2]_old = 0.7324384558991266\n",
            "Q_table[(7, 2)]_new = 0.7334912648118515\n",
            "We are on 7 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1946 episode and 16 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1947 episode and 0 step\n",
            "Delta Q = 0.9941548740311954\n",
            "Q_table[0,0]_old = 0.839685670935485\n",
            "Q_table[(0, 0)]_new = 0.8498719778731318\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1947 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1948 episode and 0 step\n",
            "Delta Q = 0.9742966545026375\n",
            "Q_table[0,1]_old = 0.8543058383234563\n",
            "Q_table[(0, 1)]_new = 0.8431719089937482\n",
            "We are on 0 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1948 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1949 episode and 0 step\n",
            "Delta Q = 0.9955784448087672\n",
            "Q_table[0,1]_old = 0.8431719089937482\n",
            "Q_table[(0, 1)]_new = 0.8544331629031405\n",
            "We are on 0 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1949 episode and 1 step\n",
            "Delta Q = 0.9955784448087672\n",
            "Q_table[8,0]_old = 0.9477642679605274\n",
            "Q_table[(8, 0)]_new = 0.948566285973242\n",
            "We are on 8 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1949 episode and 2 step\n",
            "Delta Q = 0.9955784448087672\n",
            "Q_table[8,0]_old = 0.948566285973242\n",
            "Q_table[(8, 0)]_new = 0.9492881021846851\n",
            "We are on 8 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1949 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,1]_old = 0.0\n",
            "Q_table[(8, 1)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1950 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,2]_old = 0.19696217623781997\n",
            "Q_table[(0, 2)]_new = 0.177265958614038\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1951 episode and 0 step\n",
            "Delta Q = 0.9728951358747789\n",
            "Q_table[0,3]_old = 0.793774662429748\n",
            "Q_table[(0, 3)]_new = 0.7872923320615521\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1951 episode and 1 step\n",
            "Delta Q = 0.9728951358747789\n",
            "Q_table[3,3]_old = 0.7173729372684153\n",
            "Q_table[(3, 3)]_new = 0.7185307794163527\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1951 episode and 2 step\n",
            "Delta Q = 0.9728951358747789\n",
            "Q_table[3,2]_old = 0.7201843745647187\n",
            "Q_table[(3, 2)]_new = 0.7210610729830258\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1951 episode and 3 step\n",
            "Delta Q = 0.9728951358747789\n",
            "Q_table[3,3]_old = 0.7185307794163527\n",
            "Q_table[(3, 3)]_new = 0.7195728373494964\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1951 episode and 4 step\n",
            "Delta Q = 0.9700830588365627\n",
            "Q_table[3,0]_old = 0.685935801638685\n",
            "Q_table[(3, 0)]_new = 0.6874252803113791\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1951 episode and 5 step\n",
            "Delta Q = 0.9700830588365627\n",
            "Q_table[2,3]_old = 0.6603314769115476\n",
            "Q_table[(2, 3)]_new = 0.6643813880569555\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1951 episode and 6 step\n",
            "Delta Q = 0.9700830588365627\n",
            "Q_table[2,3]_old = 0.6643813880569555\n",
            "Q_table[(2, 3)]_new = 0.6680263080878226\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1951 episode and 7 step\n",
            "Delta Q = 0.9728951358747789\n",
            "Q_table[2,2]_old = 0.707909685217804\n",
            "Q_table[(2, 2)]_new = 0.7100138525708025\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1951 episode and 8 step\n",
            "Delta Q = 0.9728951358747789\n",
            "Q_table[3,3]_old = 0.7195728373494964\n",
            "Q_table[(3, 3)]_new = 0.7205106894893257\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1951 episode and 9 step\n",
            "Delta Q = 0.9742966545026375\n",
            "Q_table[3,1]_old = 0.7363145037856457\n",
            "Q_table[(3, 1)]_new = 0.7369797079097186\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1951 episode and 10 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1952 episode and 0 step\n",
            "Delta Q = 0.9729609910830621\n",
            "Q_table[0,3]_old = 0.7872923320615521\n",
            "Q_table[(0, 3)]_new = 0.781524089938459\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1952 episode and 1 step\n",
            "Delta Q = 0.9742966545026375\n",
            "Q_table[3,1]_old = 0.7369797079097186\n",
            "Q_table[(3, 1)]_new = 0.7375783916213842\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1952 episode and 2 step\n",
            "Delta Q = 0.9742966545026375\n",
            "Q_table[7,2]_old = 0.7334912648118515\n",
            "Q_table[(7, 2)]_new = 0.7344387928333038\n",
            "We are on 7 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1952 episode and 3 step\n",
            "Delta Q = 0.9742966545026375\n",
            "Q_table[7,2]_old = 0.7344387928333038\n",
            "Q_table[(7, 2)]_new = 0.7352915680526109\n",
            "We are on 7 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1952 episode and 4 step\n",
            "Delta Q = 0.9764663206893177\n",
            "Q_table[7,1]_old = 0.7504712576023989\n",
            "Q_table[(7, 1)]_new = 0.7518904525314767\n",
            "We are on 7 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1952 episode and 5 step\n",
            "Delta Q = 0.9764663206893177\n",
            "Q_table[11,2]_old = 0.717124428897273\n",
            "Q_table[(11, 2)]_new = 0.7218783066968634\n",
            "We are on 11 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1952 episode and 6 step\n",
            "Delta Q = 0.9744371548006162\n",
            "Q_table[11,3]_old = 0.7246861184358857\n",
            "Q_table[(11, 3)]_new = 0.7266546613929133\n",
            "We are on 11 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1952 episode and 7 step\n",
            "Delta Q = 0.9744371548006162\n",
            "Q_table[7,2]_old = 0.7352915680526109\n",
            "Q_table[(7, 2)]_new = 0.736199566047966\n",
            "We are on 7 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1952 episode and 8 step\n",
            "Delta Q = 0.9730202607705171\n",
            "Q_table[7,3]_old = 0.7124930166278214\n",
            "Q_table[(7, 3)]_new = 0.7142639757355563\n",
            "We are on 7 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1952 episode and 9 step\n",
            "Delta Q = 0.9702913714045095\n",
            "Q_table[3,0]_old = 0.6874252803113791\n",
            "Q_table[(3, 0)]_new = 0.6889741236847506\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1952 episode and 10 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,1]_old = 0.0\n",
            "Q_table[(2, 1)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1953 episode and 0 step\n",
            "Delta Q = 0.9702913714045095\n",
            "Q_table[0,0]_old = 0.8498719778731318\n",
            "Q_table[(0, 0)]_new = 0.8351761514903282\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1953 episode and 1 step\n",
            "Delta Q = 0.9730202607705171\n",
            "Q_table[2,2]_old = 0.7100138525708025\n",
            "Q_table[(2, 2)]_new = 0.7120327280842393\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1953 episode and 2 step\n",
            "Delta Q = 0.9744371548006162\n",
            "Q_table[3,1]_old = 0.7375783916213842\n",
            "Q_table[(3, 1)]_new = 0.738257707259862\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1953 episode and 3 step\n",
            "Delta Q = 0.9764663206893177\n",
            "Q_table[7,1]_old = 0.7518904525314767\n",
            "Q_table[(7, 1)]_new = 0.7531677279676467\n",
            "We are on 7 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1953 episode and 4 step\n",
            "Delta Q = 0.974563605068797\n",
            "Q_table[11,3]_old = 0.7266546613929133\n",
            "Q_table[(11, 3)]_new = 0.728552800322419\n",
            "We are on 11 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1953 episode and 5 step\n",
            "Delta Q = 0.9764663206893177\n",
            "Q_table[7,1]_old = 0.7531677279676467\n",
            "Q_table[(7, 1)]_new = 0.7543172758601998\n",
            "We are on 7 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1953 episode and 6 step\n",
            "Delta Q = 0.9746774103101598\n",
            "Q_table[11,3]_old = 0.728552800322419\n",
            "Q_table[(11, 3)]_new = 0.7303749306003369\n",
            "We are on 11 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1953 episode and 7 step\n",
            "Delta Q = 0.9764663206893177\n",
            "Q_table[7,1]_old = 0.7543172758601998\n",
            "Q_table[(7, 1)]_new = 0.7553518689634975\n",
            "We are on 7 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1953 episode and 8 step\n",
            "Delta Q = 0.9747798350273863\n",
            "Q_table[11,3]_old = 0.7303749306003369\n",
            "Q_table[(11, 3)]_new = 0.7321172725676894\n",
            "We are on 11 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1953 episode and 9 step\n",
            "Delta Q = 0.9730875130187263\n",
            "Q_table[7,3]_old = 0.7142639757355563\n",
            "Q_table[(7, 3)]_new = 0.715925091180727\n",
            "We are on 7 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1953 episode and 10 step\n",
            "Delta Q = 0.9747798350273863\n",
            "Q_table[3,1]_old = 0.738257707259862\n",
            "Q_table[(3, 1)]_new = 0.739211771561262\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1953 episode and 11 step\n",
            "Delta Q = 0.9747798350273863\n",
            "Q_table[7,2]_old = 0.736199566047966\n",
            "Q_table[(7, 2)]_new = 0.7373594444705557\n",
            "We are on 7 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1953 episode and 12 step\n",
            "Delta Q = 0.9731819653845649\n",
            "Q_table[7,3]_old = 0.715925091180727\n",
            "Q_table[(7, 3)]_new = 0.7175145474472192\n",
            "We are on 7 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1953 episode and 13 step\n",
            "Delta Q = 0.9747798350273863\n",
            "Q_table[3,1]_old = 0.739211771561262\n",
            "Q_table[(3, 1)]_new = 0.7400704294325221\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1953 episode and 14 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1954 episode and 0 step\n",
            "Delta Q = 0.9941548740311954\n",
            "Q_table[0,0]_old = 0.8351761514903282\n",
            "Q_table[(0, 0)]_new = 0.8458134103724908\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1954 episode and 1 step\n",
            "Delta Q = 0.9955784448087672\n",
            "Q_table[4,1]_old = 0.9510593336484376\n",
            "Q_table[(4, 1)]_new = 0.9515318450923611\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1954 episode and 2 step\n",
            "Delta Q = 0.9942016526641437\n",
            "Q_table[8,3]_old = 0.9318094041573339\n",
            "Q_table[(8, 3)]_new = 0.9328301164057444\n",
            "We are on 8 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1954 episode and 3 step\n",
            "Delta Q = 0.9955784448087672\n",
            "Q_table[4,1]_old = 0.9515318450923611\n",
            "Q_table[(4, 1)]_new = 0.9519571053918923\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1954 episode and 4 step\n",
            "Delta Q = 0.9971934476404913\n",
            "Q_table[8,2]_old = 0.9654388364521945\n",
            "Q_table[(8, 2)]_new = 0.9660884004474664\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1954 episode and 5 step\n",
            "Delta Q = 1.0\n",
            "Q_table[9,1]_old = 0.9817519963685992\n",
            "Q_table[(9, 1)]_new = 0.9835767967317393\n",
            "We are on 9 state\n",
            "And now we are on 13 state\n",
            "We get 1.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1955 episode and 0 step\n",
            "Delta Q = 0.9956427516442992\n",
            "Q_table[0,1]_old = 0.8544331629031405\n",
            "Q_table[(0, 1)]_new = 0.8646325982571257\n",
            "We are on 0 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1955 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,1]_old = 0.0\n",
            "Q_table[(8, 1)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1956 episode and 0 step\n",
            "Delta Q = 0.9855986272274555\n",
            "Q_table[0,3]_old = 0.781524089938459\n",
            "Q_table[(0, 3)]_new = 0.7889703081720686\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1956 episode and 1 step\n",
            "Delta Q = 0.9942437534337973\n",
            "Q_table[0,1]_old = 0.8646325982571257\n",
            "Q_table[(0, 1)]_new = 0.8724130918652104\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1956 episode and 2 step\n",
            "Delta Q = 0.9956427516442992\n",
            "Q_table[4,1]_old = 0.9519571053918923\n",
            "Q_table[(4, 1)]_new = 0.9524041464970022\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1956 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,1]_old = 0.0\n",
            "Q_table[(8, 1)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1957 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,2]_old = 0.177265958614038\n",
            "Q_table[(0, 2)]_new = 0.1595393627526342\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1958 episode and 0 step\n",
            "Delta Q = 0.9732669725138197\n",
            "Q_table[0,2]_old = 0.1595393627526342\n",
            "Q_table[(0, 2)]_new = 0.21685239899119046\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1958 episode and 1 step\n",
            "Delta Q = 0.9732669725138197\n",
            "Q_table[3,2]_old = 0.7210610729830258\n",
            "Q_table[(3, 2)]_new = 0.7222219381985429\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1958 episode and 2 step\n",
            "Delta Q = 0.9732669725138197\n",
            "Q_table[3,2]_old = 0.7222219381985429\n",
            "Q_table[(3, 2)]_new = 0.7232667168925082\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1958 episode and 3 step\n",
            "Delta Q = 0.9747798350273863\n",
            "Q_table[3,1]_old = 0.7400704294325221\n",
            "Q_table[(3, 1)]_new = 0.7408432215166562\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1958 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1959 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,2]_old = 0.21685239899119046\n",
            "Q_table[(0, 2)]_new = 0.1951671590920714\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1960 episode and 0 step\n",
            "Delta Q = 0.9747798350273863\n",
            "Q_table[0,1]_old = 0.8724130918652104\n",
            "Q_table[(0, 1)]_new = 0.8599516177060756\n",
            "We are on 0 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1960 episode and 1 step\n",
            "Delta Q = 0.9747798350273863\n",
            "Q_table[7,2]_old = 0.7373594444705557\n",
            "Q_table[(7, 2)]_new = 0.7384033350508864\n",
            "We are on 7 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1960 episode and 2 step\n",
            "Delta Q = 0.9764663206893177\n",
            "Q_table[7,1]_old = 0.7553518689634975\n",
            "Q_table[(7, 1)]_new = 0.7562830027564654\n",
            "We are on 7 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1960 episode and 3 step\n",
            "Delta Q = 0.9805946969506241\n",
            "Q_table[11,1]_old = 0.7723870776698754\n",
            "Q_table[(11, 1)]_new = 0.7757430668535119\n",
            "We are on 11 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1960 episode and 4 step\n",
            "Delta Q = 0.9805946969506241\n",
            "Q_table[15,2]_old = 0.7423126897941282\n",
            "Q_table[(15, 2)]_new = 0.7486761177653395\n",
            "We are on 15 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1960 episode and 5 step\n",
            "Delta Q = 0.9805946969506241\n",
            "Q_table[15,2]_old = 0.7486761177653395\n",
            "Q_table[(15, 2)]_new = 0.7544032029394296\n",
            "We are on 15 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1960 episode and 6 step\n",
            "Delta Q = 0.9805946969506241\n",
            "Q_table[15,1]_old = 0.7322908938008894\n",
            "Q_table[(15, 1)]_new = 0.7396565013714246\n",
            "We are on 15 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1960 episode and 7 step\n",
            "Delta Q = 0.9767985636184977\n",
            "Q_table[15,3]_old = 0.712334238910382\n",
            "Q_table[(15, 3)]_new = 0.7178993786378415\n",
            "We are on 15 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1960 episode and 8 step\n",
            "Delta Q = 0.9805946969506241\n",
            "Q_table[11,1]_old = 0.7757430668535119\n",
            "Q_table[(11, 1)]_new = 0.7787634571187848\n",
            "We are on 11 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1960 episode and 9 step\n",
            "Delta Q = 0.9805946969506241\n",
            "Q_table[15,1]_old = 0.7396565013714246\n",
            "Q_table[(15, 1)]_new = 0.7462855481849062\n",
            "We are on 15 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1960 episode and 10 step\n",
            "Delta Q = 0.9805946969506241\n",
            "Q_table[15,2]_old = 0.7544032029394296\n",
            "Q_table[(15, 2)]_new = 0.7595575795961107\n",
            "We are on 15 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1960 episode and 11 step\n",
            "Delta Q = 0.9805946969506241\n",
            "Q_table[15,1]_old = 0.7462855481849062\n",
            "Q_table[(15, 1)]_new = 0.7522516903170396\n",
            "We are on 15 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1960 episode and 12 step\n",
            "Delta Q = 0.9805946969506241\n",
            "Q_table[15,1]_old = 0.7522516903170396\n",
            "Q_table[(15, 1)]_new = 0.7576212182359597\n",
            "We are on 15 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1960 episode and 13 step\n",
            "Delta Q = 0.9805946969506241\n",
            "Q_table[15,1]_old = 0.7576212182359597\n",
            "Q_table[(15, 1)]_new = 0.7624537933629878\n",
            "We are on 15 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1960 episode and 14 step\n",
            "Delta Q = 0.9805946969506241\n",
            "Q_table[15,1]_old = 0.7624537933629878\n",
            "Q_table[(15, 1)]_new = 0.7668031109773131\n",
            "We are on 15 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1960 episode and 15 step\n",
            "Delta Q = 0.9805946969506241\n",
            "Q_table[15,2]_old = 0.7595575795961107\n",
            "Q_table[(15, 2)]_new = 0.7641965185871237\n",
            "We are on 15 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1960 episode and 16 step\n",
            "Delta Q = 0.9869639111955337\n",
            "Q_table[15,0]_old = 0.8140878479861018\n",
            "Q_table[(15, 0)]_new = 0.8196429743830254\n",
            "We are on 15 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1960 episode and 17 step\n",
            "Delta Q = 1.0\n",
            "Q_table[14,0]_old = 0.8784233454094308\n",
            "Q_table[(14, 0)]_new = 0.8905810108684877\n",
            "We are on 14 state\n",
            "And now we are on 13 state\n",
            "We get 1.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1961 episode and 0 step\n",
            "Delta Q = 0.9851352101529015\n",
            "Q_table[0,3]_old = 0.7889703081720686\n",
            "Q_table[(0, 3)]_new = 0.7952084875077632\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1961 episode and 1 step\n",
            "Delta Q = 0.9851352101529015\n",
            "Q_table[0,0]_old = 0.8458134103724908\n",
            "Q_table[(0, 0)]_new = 0.8463672794881433\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1961 episode and 2 step\n",
            "Delta Q = 0.9851352101529015\n",
            "Q_table[0,3]_old = 0.7952084875077632\n",
            "Q_table[(0, 3)]_new = 0.8008228489098884\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1961 episode and 3 step\n",
            "Delta Q = 0.9942880105032033\n",
            "Q_table[0,1]_old = 0.8599516177060756\n",
            "Q_table[(0, 1)]_new = 0.8682444664386714\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1961 episode and 4 step\n",
            "Delta Q = 0.9956427516442992\n",
            "Q_table[4,1]_old = 0.9524041464970022\n",
            "Q_table[(4, 1)]_new = 0.9528064834916011\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1961 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,1]_old = 0.0\n",
            "Q_table[(8, 1)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1962 episode and 0 step\n",
            "Delta Q = 0.9748720172728901\n",
            "Q_table[0,1]_old = 0.8682444664386714\n",
            "Q_table[(0, 1)]_new = 0.8562920370676943\n",
            "We are on 0 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1962 episode and 1 step\n",
            "Delta Q = 0.9733434789301489\n",
            "Q_table[7,3]_old = 0.7175145474472192\n",
            "Q_table[(7, 3)]_new = 0.7191065716326462\n",
            "We are on 7 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1962 episode and 2 step\n",
            "Delta Q = 0.9733434789301489\n",
            "Q_table[3,3]_old = 0.7205106894893257\n",
            "Q_table[(3, 3)]_new = 0.7218030994705421\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1962 episode and 3 step\n",
            "Delta Q = 0.9733434789301489\n",
            "Q_table[3,2]_old = 0.7232667168925082\n",
            "Q_table[(3, 2)]_new = 0.7242835241334064\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1962 episode and 4 step\n",
            "Delta Q = 0.9704912400803397\n",
            "Q_table[3,0]_old = 0.6889741236847506\n",
            "Q_table[(3, 0)]_new = 0.6905679513966153\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1962 episode and 5 step\n",
            "Delta Q = 0.9733434789301489\n",
            "Q_table[2,2]_old = 0.7120327280842393\n",
            "Q_table[(2, 2)]_new = 0.7141729342059644\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1962 episode and 6 step\n",
            "Delta Q = 0.9707031204863905\n",
            "Q_table[3,0]_old = 0.6905679513966153\n",
            "Q_table[(3, 0)]_new = 0.6922142767433442\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1962 episode and 7 step\n",
            "Delta Q = 0.9733434789301489\n",
            "Q_table[2,2]_old = 0.7141729342059644\n",
            "Q_table[(2, 2)]_new = 0.7160991197155169\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1962 episode and 8 step\n",
            "Delta Q = 0.9748720172728901\n",
            "Q_table[3,1]_old = 0.7408432215166562\n",
            "Q_table[(3, 1)]_new = 0.7416309166378806\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1962 episode and 9 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1963 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,2]_old = 0.1951671590920714\n",
            "Q_table[(0, 2)]_new = 0.17565044318286427\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1964 episode and 0 step\n",
            "Delta Q = 0.9943278418656686\n",
            "Q_table[0,0]_old = 0.8463672794881433\n",
            "Q_table[(0, 0)]_new = 0.8560583934049976\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1964 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1965 episode and 0 step\n",
            "Delta Q = 0.9943278418656686\n",
            "Q_table[0,0]_old = 0.8560583934049976\n",
            "Q_table[(0, 0)]_new = 0.8647803959301664\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1965 episode and 1 step\n",
            "Delta Q = 0.9856132591970865\n",
            "Q_table[4,3]_old = 0.8526839064242072\n",
            "Q_table[(4, 3)]_new = 0.853028774978873\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1965 episode and 2 step\n",
            "Delta Q = 0.9856132591970865\n",
            "Q_table[0,0]_old = 0.8647803959301664\n",
            "Q_table[(0, 0)]_new = 0.8639156155342363\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1965 episode and 3 step\n",
            "Delta Q = 0.9943278418656686\n",
            "Q_table[0,1]_old = 0.8562920370676943\n",
            "Q_table[(0, 1)]_new = 0.8649906752265935\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1965 episode and 4 step\n",
            "Delta Q = 0.9956427516442992\n",
            "Q_table[4,1]_old = 0.9528064834916011\n",
            "Q_table[(4, 1)]_new = 0.9531685867867402\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1965 episode and 5 step\n",
            "Delta Q = 0.9943636900918873\n",
            "Q_table[8,3]_old = 0.9328301164057444\n",
            "Q_table[(8, 3)]_new = 0.9339107948570573\n",
            "We are on 8 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1965 episode and 6 step\n",
            "Delta Q = 0.9856340768474328\n",
            "Q_table[4,3]_old = 0.853028774978873\n",
            "Q_table[(4, 3)]_new = 0.8533599743284185\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1965 episode and 7 step\n",
            "Delta Q = 0.9856340768474328\n",
            "Q_table[0,3]_old = 0.8008228489098884\n",
            "Q_table[(0, 3)]_new = 0.8063746408663324\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1965 episode and 8 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,2]_old = 0.17565044318286427\n",
            "Q_table[(0, 2)]_new = 0.15808539886457784\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1966 episode and 0 step\n",
            "Delta Q = 0.9943636900918873\n",
            "Q_table[0,0]_old = 0.8639156155342363\n",
            "Q_table[(0, 0)]_new = 0.8718877440727\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1966 episode and 1 step\n",
            "Delta Q = 0.9956427516442992\n",
            "Q_table[4,1]_old = 0.9531685867867402\n",
            "Q_table[(4, 1)]_new = 0.9534944797523653\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1966 episode and 2 step\n",
            "Delta Q = 0.9973741028764422\n",
            "Q_table[8,2]_old = 0.9660884004474664\n",
            "Q_table[(8, 2)]_new = 0.966853663279162\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1966 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[9,2]_old = 0.0\n",
            "Q_table[(9, 2)]_new = 0.0\n",
            "We are on 9 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1967 episode and 0 step\n",
            "Delta Q = 0.9734214607471502\n",
            "Q_table[0,3]_old = 0.8063746408663324\n",
            "Q_table[(0, 3)]_new = 0.7991586375268493\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1967 episode and 1 step\n",
            "Delta Q = 0.9708938128518362\n",
            "Q_table[3,0]_old = 0.6922142767433442\n",
            "Q_table[(3, 0)]_new = 0.693886661920846\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1967 episode and 2 step\n",
            "Delta Q = 0.9734214607471502\n",
            "Q_table[2,2]_old = 0.7160991197155169\n",
            "Q_table[(2, 2)]_new = 0.7179106684911154\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1967 episode and 3 step\n",
            "Delta Q = 0.9734214607471502\n",
            "Q_table[3,2]_old = 0.7242835241334064\n",
            "Q_table[(3, 2)]_new = 0.7252766324672159\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1967 episode and 4 step\n",
            "Delta Q = 0.9734214607471502\n",
            "Q_table[3,3]_old = 0.7218030994705421\n",
            "Q_table[(3, 3)]_new = 0.7230442502706381\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1967 episode and 5 step\n",
            "Delta Q = 0.9734214607471502\n",
            "Q_table[3,2]_old = 0.7252766324672159\n",
            "Q_table[(3, 2)]_new = 0.7261704299676445\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1967 episode and 6 step\n",
            "Delta Q = 0.9734214607471502\n",
            "Q_table[3,3]_old = 0.7230442502706381\n",
            "Q_table[(3, 3)]_new = 0.7241612859907245\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1967 episode and 7 step\n",
            "Delta Q = 0.9734214607471502\n",
            "Q_table[3,2]_old = 0.7261704299676445\n",
            "Q_table[(3, 2)]_new = 0.7269748477180302\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1967 episode and 8 step\n",
            "Delta Q = 0.9734214607471502\n",
            "Q_table[3,3]_old = 0.7241612859907245\n",
            "Q_table[(3, 3)]_new = 0.7251666181388022\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1967 episode and 9 step\n",
            "Delta Q = 0.9710731561806204\n",
            "Q_table[3,0]_old = 0.693886661920846\n",
            "Q_table[(3, 0)]_new = 0.6955711519093818\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1967 episode and 10 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,0]_old = 0.0\n",
            "Q_table[(2, 0)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1968 episode and 0 step\n",
            "Delta Q = 0.9863168866631973\n",
            "Q_table[0,3]_old = 0.7991586375268493\n",
            "Q_table[(0, 3)]_new = 0.8055596604373618\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1968 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,2]_old = 0.15808539886457784\n",
            "Q_table[(0, 2)]_new = 0.14227685897812006\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1969 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,2]_old = 0.14227685897812006\n",
            "Q_table[(0, 2)]_new = 0.12804917308030805\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1970 episode and 0 step\n",
            "Delta Q = 0.9943959534954842\n",
            "Q_table[0,0]_old = 0.8718877440727\n",
            "Q_table[(0, 0)]_new = 0.8790949231609141\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1970 episode and 1 step\n",
            "Delta Q = 0.9943959534954842\n",
            "Q_table[4,0]_old = 0.9353080559094\n",
            "Q_table[(4, 0)]_new = 0.9361732038139442\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1970 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1971 episode and 0 step\n",
            "Delta Q = 0.9748720172728901\n",
            "Q_table[0,1]_old = 0.8649906752265935\n",
            "Q_table[(0, 1)]_new = 0.8533636249768242\n",
            "We are on 0 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1971 episode and 1 step\n",
            "Delta Q = 0.9734214607471502\n",
            "Q_table[7,3]_old = 0.7191065716326462\n",
            "Q_table[(7, 3)]_new = 0.7206173752165318\n",
            "We are on 7 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1971 episode and 2 step\n",
            "Delta Q = 0.9734214607471502\n",
            "Q_table[3,3]_old = 0.7251666181388022\n",
            "Q_table[(3, 3)]_new = 0.7260714170720722\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1971 episode and 3 step\n",
            "Delta Q = 0.9710731561806204\n",
            "Q_table[3,0]_old = 0.6955711519093818\n",
            "Q_table[(3, 0)]_new = 0.697087192899064\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1971 episode and 4 step\n",
            "Delta Q = 0.9734214607471502\n",
            "Q_table[2,2]_old = 0.7179106684911154\n",
            "Q_table[(2, 2)]_new = 0.719541062389154\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1971 episode and 5 step\n",
            "Delta Q = 0.9734214607471502\n",
            "Q_table[3,2]_old = 0.7269748477180302\n",
            "Q_table[(3, 2)]_new = 0.7276988236933774\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1971 episode and 6 step\n",
            "Delta Q = 0.9734214607471502\n",
            "Q_table[3,2]_old = 0.7276988236933774\n",
            "Q_table[(3, 2)]_new = 0.7283504020711898\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1971 episode and 7 step\n",
            "Delta Q = 0.9734214607471502\n",
            "Q_table[3,2]_old = 0.7283504020711898\n",
            "Q_table[(3, 2)]_new = 0.7289368226112211\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1971 episode and 8 step\n",
            "Delta Q = 0.9734214607471502\n",
            "Q_table[3,3]_old = 0.7260714170720722\n",
            "Q_table[(3, 3)]_new = 0.7268857361120152\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1971 episode and 9 step\n",
            "Delta Q = 0.9712345651765263\n",
            "Q_table[3,0]_old = 0.697087192899064\n",
            "Q_table[(3, 0)]_new = 0.6986130387856838\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1971 episode and 10 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,0]_old = 0.0\n",
            "Q_table[(2, 0)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1972 episode and 0 step\n",
            "Delta Q = 0.9712345651765263\n",
            "Q_table[0,0]_old = 0.8790949231609141\n",
            "Q_table[(0, 0)]_new = 0.862419996021349\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1972 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,1]_old = 0.0\n",
            "Q_table[(2, 1)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1973 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,2]_old = 0.12804917308030805\n",
            "Q_table[(0, 2)]_new = 0.11524425577227725\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1974 episode and 0 step\n",
            "Delta Q = 0.9712345651765263\n",
            "Q_table[0,0]_old = 0.862419996021349\n",
            "Q_table[(0, 0)]_new = 0.8474125615957404\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1974 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,1]_old = 0.0\n",
            "Q_table[(2, 1)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1975 episode and 0 step\n",
            "Delta Q = 0.9712345651765263\n",
            "Q_table[0,0]_old = 0.8474125615957404\n",
            "Q_table[(0, 0)]_new = 0.8339058706126926\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1975 episode and 1 step\n",
            "Delta Q = 0.9734214607471502\n",
            "Q_table[2,2]_old = 0.719541062389154\n",
            "Q_table[(2, 2)]_new = 0.7210084168973888\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1975 episode and 2 step\n",
            "Delta Q = 0.9734214607471502\n",
            "Q_table[3,2]_old = 0.7289368226112211\n",
            "Q_table[(3, 2)]_new = 0.7294646010972491\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1975 episode and 3 step\n",
            "Delta Q = 0.9734214607471502\n",
            "Q_table[3,2]_old = 0.7294646010972491\n",
            "Q_table[(3, 2)]_new = 0.7299396017346743\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1975 episode and 4 step\n",
            "Delta Q = 0.9734214607471502\n",
            "Q_table[3,2]_old = 0.7299396017346743\n",
            "Q_table[(3, 2)]_new = 0.7303671023083571\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1975 episode and 5 step\n",
            "Delta Q = 0.9734214607471502\n",
            "Q_table[3,3]_old = 0.7268857361120152\n",
            "Q_table[(3, 3)]_new = 0.7276186232479639\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1975 episode and 6 step\n",
            "Delta Q = 0.9713798332728415\n",
            "Q_table[3,0]_old = 0.6986130387856838\n",
            "Q_table[(3, 0)]_new = 0.7001315681799569\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1975 episode and 7 step\n",
            "Delta Q = 0.9713798332728415\n",
            "Q_table[2,3]_old = 0.6680263080878226\n",
            "Q_table[(2, 3)]_new = 0.6726035105518818\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1975 episode and 8 step\n",
            "Delta Q = 0.9713798332728415\n",
            "Q_table[2,3]_old = 0.6726035105518818\n",
            "Q_table[(2, 3)]_new = 0.6767229927695352\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1975 episode and 9 step\n",
            "Delta Q = 0.9734214607471502\n",
            "Q_table[2,2]_old = 0.7210084168973888\n",
            "Q_table[(2, 2)]_new = 0.7223290359548001\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1975 episode and 10 step\n",
            "Delta Q = 0.9734214607471502\n",
            "Q_table[3,3]_old = 0.7276186232479639\n",
            "Q_table[(3, 3)]_new = 0.7282782216703176\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1975 episode and 11 step\n",
            "Delta Q = 0.9734214607471502\n",
            "Q_table[3,2]_old = 0.7303671023083571\n",
            "Q_table[(3, 2)]_new = 0.7307518528246716\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1975 episode and 12 step\n",
            "Delta Q = 0.9715105745595253\n",
            "Q_table[3,0]_old = 0.7001315681799569\n",
            "Q_table[(3, 0)]_new = 0.7016289859214865\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1975 episode and 13 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,0]_old = 0.0\n",
            "Q_table[(2, 0)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1976 episode and 0 step\n",
            "Delta Q = 0.9943959534954842\n",
            "Q_table[0,0]_old = 0.8339058706126926\n",
            "Q_table[(0, 0)]_new = 0.8449112370469075\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1976 episode and 1 step\n",
            "Delta Q = 0.9844829988727056\n",
            "Q_table[4,3]_old = 0.8533599743284185\n",
            "Q_table[(4, 3)]_new = 0.8525069757682823\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1976 episode and 2 step\n",
            "Delta Q = 0.9844829988727056\n",
            "Q_table[0,3]_old = 0.8055596604373618\n",
            "Q_table[(0, 3)]_new = 0.8094866932663313\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1976 episode and 3 step\n",
            "Delta Q = 0.9943959534954842\n",
            "Q_table[0,1]_old = 0.8533636249768242\n",
            "Q_table[(0, 1)]_new = 0.8624232159746259\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1976 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1977 episode and 0 step\n",
            "Delta Q = 0.9748720172728901\n",
            "Q_table[0,1]_old = 0.8624232159746259\n",
            "Q_table[(0, 1)]_new = 0.8510529116500534\n",
            "We are on 0 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1977 episode and 1 step\n",
            "Delta Q = 0.9748720172728901\n",
            "Q_table[7,2]_old = 0.7384033350508864\n",
            "Q_table[(7, 2)]_new = 0.7394350188186878\n",
            "We are on 7 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1977 episode and 2 step\n",
            "Delta Q = 0.9770975822547597\n",
            "Q_table[7,1]_old = 0.7562830027564654\n",
            "Q_table[(7, 1)]_new = 0.7577522847355787\n",
            "We are on 7 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1977 episode and 3 step\n",
            "Delta Q = 0.9770975822547597\n",
            "Q_table[11,2]_old = 0.7218783066968634\n",
            "Q_table[(11, 2)]_new = 0.7267880582819367\n",
            "We are on 11 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1977 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[11,0]_old = 0.0\n",
            "Q_table[(11, 0)]_new = 0.0\n",
            "We are on 11 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1978 episode and 0 step\n",
            "Delta Q = 0.9842542382533553\n",
            "Q_table[0,3]_old = 0.8094866932663313\n",
            "Q_table[(0, 3)]_new = 0.8127922621930534\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1978 episode and 1 step\n",
            "Delta Q = 0.9842542382533553\n",
            "Q_table[0,0]_old = 0.8449112370469075\n",
            "Q_table[(0, 0)]_new = 0.8446743515955721\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1978 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,2]_old = 0.11524425577227725\n",
            "Q_table[(0, 2)]_new = 0.10371983019504952\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1979 episode and 0 step\n",
            "Delta Q = 0.9957185126646371\n",
            "Q_table[0,1]_old = 0.8510529116500534\n",
            "Q_table[(0, 1)]_new = 0.8616661331496851\n",
            "We are on 0 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1979 episode and 1 step\n",
            "Delta Q = 0.9943959534954842\n",
            "Q_table[8,3]_old = 0.9339107948570573\n",
            "Q_table[(8, 3)]_new = 0.9349156688668357\n",
            "We are on 8 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1979 episode and 2 step\n",
            "Delta Q = 0.9943959534954842\n",
            "Q_table[4,0]_old = 0.9361732038139442\n",
            "Q_table[(4, 0)]_new = 0.936951836928034\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1979 episode and 3 step\n",
            "Delta Q = 0.9853049471818188\n",
            "Q_table[4,3]_old = 0.8525069757682823\n",
            "Q_table[(4, 3)]_new = 0.8525612253732728\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1979 episode and 4 step\n",
            "Delta Q = 0.9853049471818188\n",
            "Q_table[0,3]_old = 0.8127922621930534\n",
            "Q_table[(0, 3)]_new = 0.816817983155567\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1979 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,2]_old = 0.10371983019504952\n",
            "Q_table[(0, 2)]_new = 0.09334784717554456\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1980 episode and 0 step\n",
            "Delta Q = 0.9853049471818188\n",
            "Q_table[0,3]_old = 0.816817983155567\n",
            "Q_table[(0, 3)]_new = 0.8204411320218291\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1980 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,2]_old = 0.09334784717554456\n",
            "Q_table[(0, 2)]_new = 0.0840130624579901\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1981 episode and 0 step\n",
            "Delta Q = 0.9750174761888223\n",
            "Q_table[0,1]_old = 0.8616661331496851\n",
            "Q_table[(0, 1)]_new = 0.8505169960235389\n",
            "We are on 0 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1981 episode and 1 step\n",
            "Delta Q = 0.9750174761888223\n",
            "Q_table[7,2]_old = 0.7394350188186878\n",
            "Q_table[(7, 2)]_new = 0.7405089931256413\n",
            "We are on 7 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1981 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1982 episode and 0 step\n",
            "Delta Q = 0.9957185126646371\n",
            "Q_table[0,1]_old = 0.8505169960235389\n",
            "Q_table[(0, 1)]_new = 0.861183809085822\n",
            "We are on 0 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1982 episode and 1 step\n",
            "Delta Q = 0.9943959534954842\n",
            "Q_table[8,3]_old = 0.9349156688668357\n",
            "Q_table[(8, 3)]_new = 0.9358200554756363\n",
            "We are on 8 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1982 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1983 episode and 0 step\n",
            "Delta Q = 0.9750174761888223\n",
            "Q_table[0,1]_old = 0.861183809085822\n",
            "Q_table[(0, 1)]_new = 0.8500829043660622\n",
            "We are on 0 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1983 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1984 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,2]_old = 0.0840130624579901\n",
            "Q_table[(0, 2)]_new = 0.0756117562121911\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1985 episode and 0 step\n",
            "Delta Q = 0.9734214607471502\n",
            "Q_table[0,3]_old = 0.8204411320218291\n",
            "Q_table[(0, 3)]_new = 0.8118184795667964\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1985 episode and 1 step\n",
            "Delta Q = 0.9734214607471502\n",
            "Q_table[3,2]_old = 0.7307518528246716\n",
            "Q_table[(3, 2)]_new = 0.7310981282893546\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1985 episode and 2 step\n",
            "Delta Q = 0.9750174761888223\n",
            "Q_table[3,1]_old = 0.7416309166378806\n",
            "Q_table[(3, 1)]_new = 0.7424853011629148\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1985 episode and 3 step\n",
            "Delta Q = 0.9735060448151286\n",
            "Q_table[7,3]_old = 0.7206173752165318\n",
            "Q_table[(7, 3)]_new = 0.7220616825100072\n",
            "We are on 7 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1985 episode and 4 step\n",
            "Delta Q = 0.9715105745595253\n",
            "Q_table[3,0]_old = 0.7016289859214865\n",
            "Q_table[(3, 0)]_new = 0.7029766618888631\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1985 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,1]_old = 0.0\n",
            "Q_table[(2, 1)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1986 episode and 0 step\n",
            "Delta Q = 0.9750174761888223\n",
            "Q_table[0,1]_old = 0.8500829043660622\n",
            "Q_table[(0, 1)]_new = 0.8400920901182782\n",
            "We are on 0 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1986 episode and 1 step\n",
            "Delta Q = 0.9735060448151286\n",
            "Q_table[7,3]_old = 0.7220616825100072\n",
            "Q_table[(7, 3)]_new = 0.7233615590741351\n",
            "We are on 7 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1986 episode and 2 step\n",
            "Delta Q = 0.9750174761888223\n",
            "Q_table[3,1]_old = 0.7424853011629148\n",
            "Q_table[(3, 1)]_new = 0.7432542472354455\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1986 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1987 episode and 0 step\n",
            "Delta Q = 0.9715105745595253\n",
            "Q_table[0,0]_old = 0.8446743515955721\n",
            "Q_table[(0, 0)]_new = 0.8317174909955402\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1987 episode and 1 step\n",
            "Delta Q = 0.9735821704763091\n",
            "Q_table[2,2]_old = 0.7223290359548001\n",
            "Q_table[(2, 2)]_new = 0.7236783028356293\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1987 episode and 2 step\n",
            "Delta Q = 0.9735821704763091\n",
            "Q_table[3,3]_old = 0.7282782216703176\n",
            "Q_table[(3, 3)]_new = 0.729032569979595\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1987 episode and 3 step\n",
            "Delta Q = 0.9750174761888223\n",
            "Q_table[3,1]_old = 0.7432542472354455\n",
            "Q_table[(3, 1)]_new = 0.7439462987007233\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1987 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1988 episode and 0 step\n",
            "Delta Q = 0.9736506835713716\n",
            "Q_table[0,2]_old = 0.0756117562121911\n",
            "Q_table[(0, 2)]_new = 0.14170126416234358\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1988 episode and 1 step\n",
            "Delta Q = 0.9750174761888223\n",
            "Q_table[3,1]_old = 0.7439462987007233\n",
            "Q_table[(3, 1)]_new = 0.7445691450194732\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1988 episode and 2 step\n",
            "Delta Q = 0.9737123453569279\n",
            "Q_table[7,3]_old = 0.7233615590741351\n",
            "Q_table[(7, 3)]_new = 0.7247377485236495\n",
            "We are on 7 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1988 episode and 3 step\n",
            "Delta Q = 0.9716441519807273\n",
            "Q_table[3,0]_old = 0.7029766618888631\n",
            "Q_table[(3, 0)]_new = 0.704323147680704\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1988 episode and 4 step\n",
            "Delta Q = 0.9716441519807273\n",
            "Q_table[2,3]_old = 0.6767229927695352\n",
            "Q_table[(2, 3)]_new = 0.6806948454733089\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1988 episode and 5 step\n",
            "Delta Q = 0.9716441519807273\n",
            "Q_table[2,3]_old = 0.6806948454733089\n",
            "Q_table[(2, 3)]_new = 0.6842695129067053\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1988 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,1]_old = 0.0\n",
            "Q_table[(2, 1)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1989 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,2]_old = 0.14170126416234358\n",
            "Q_table[(0, 2)]_new = 0.12753113774610922\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1990 episode and 0 step\n",
            "Delta Q = 0.9831691169217096\n",
            "Q_table[0,3]_old = 0.8118184795667964\n",
            "Q_table[(0, 3)]_new = 0.8138057485318264\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1990 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,2]_old = 0.12753113774610922\n",
            "Q_table[(0, 2)]_new = 0.1147780239714983\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1991 episode and 0 step\n",
            "Delta Q = 0.9716441519807273\n",
            "Q_table[0,0]_old = 0.8317174909955402\n",
            "Q_table[(0, 0)]_new = 0.8201898938767134\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1991 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,0]_old = 0.0\n",
            "Q_table[(2, 0)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1992 episode and 0 step\n",
            "Delta Q = 0.9943959534954842\n",
            "Q_table[0,0]_old = 0.8201898938767134\n",
            "Q_table[(0, 0)]_new = 0.8325668579845262\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1992 episode and 1 step\n",
            "Delta Q = 0.9957185126646371\n",
            "Q_table[4,1]_old = 0.9534944797523653\n",
            "Q_table[(4, 1)]_new = 0.9538635444417659\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1992 episode and 2 step\n",
            "Delta Q = 0.9957185126646371\n",
            "Q_table[8,0]_old = 0.9492881021846851\n",
            "Q_table[(8, 0)]_new = 0.9500778046308537\n",
            "We are on 8 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1992 episode and 3 step\n",
            "Delta Q = 0.9944324908997348\n",
            "Q_table[8,3]_old = 0.9358200554756363\n",
            "Q_table[(8, 3)]_new = 0.9366705408278075\n",
            "We are on 8 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1992 episode and 4 step\n",
            "Delta Q = 0.9944324908997348\n",
            "Q_table[4,0]_old = 0.936951836928034\n",
            "Q_table[(4, 0)]_new = 0.9376891441349654\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1992 episode and 5 step\n",
            "Delta Q = 0.9831691169217096\n",
            "Q_table[4,3]_old = 0.8525612253732728\n",
            "Q_table[(4, 3)]_new = 0.8504742197576551\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1992 episode and 6 step\n",
            "Delta Q = 0.9944324908997348\n",
            "Q_table[0,1]_old = 0.8400920901182782\n",
            "Q_table[(0, 1)]_new = 0.8505153720061852\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1992 episode and 7 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1993 episode and 0 step\n",
            "Delta Q = 0.9737123453569279\n",
            "Q_table[0,2]_old = 0.1147780239714983\n",
            "Q_table[(0, 2)]_new = 0.17701256693127634\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1993 episode and 1 step\n",
            "Delta Q = 0.9737123453569279\n",
            "Q_table[3,2]_old = 0.7310981282893546\n",
            "Q_table[(3, 2)]_new = 0.731700660817347\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1993 episode and 2 step\n",
            "Delta Q = 0.9750174761888223\n",
            "Q_table[3,1]_old = 0.7445691450194732\n",
            "Q_table[(3, 1)]_new = 0.7451297067063481\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1993 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1994 episode and 0 step\n",
            "Delta Q = 0.9944324908997348\n",
            "Q_table[0,0]_old = 0.8325668579845262\n",
            "Q_table[(0, 0)]_new = 0.8437426630858085\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1994 episode and 1 step\n",
            "Delta Q = 0.9944324908997348\n",
            "Q_table[4,0]_old = 0.9376891441349654\n",
            "Q_table[(4, 0)]_new = 0.9383527206212037\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1994 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1995 episode and 0 step\n",
            "Delta Q = 0.9737678409639285\n",
            "Q_table[0,2]_old = 0.17701256693127634\n",
            "Q_table[(0, 2)]_new = 0.23307915120207717\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1995 episode and 1 step\n",
            "Delta Q = 0.9716441519807273\n",
            "Q_table[3,0]_old = 0.704323147680704\n",
            "Q_table[(3, 0)]_new = 0.7055349848933609\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1995 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,0]_old = 0.0\n",
            "Q_table[(2, 0)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1996 episode and 0 step\n",
            "Delta Q = 0.9944324908997348\n",
            "Q_table[0,0]_old = 0.8437426630858085\n",
            "Q_table[(0, 0)]_new = 0.8538008876769625\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1996 episode and 1 step\n",
            "Delta Q = 0.9944324908997348\n",
            "Q_table[4,0]_old = 0.9383527206212037\n",
            "Q_table[(4, 0)]_new = 0.9389499394588181\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1996 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1997 episode and 0 step\n",
            "Delta Q = 0.9750174761888223\n",
            "Q_table[0,1]_old = 0.8505153720061852\n",
            "Q_table[(0, 1)]_new = 0.8404813109943889\n",
            "We are on 0 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1997 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1998 episode and 0 step\n",
            "Delta Q = 0.9750174761888223\n",
            "Q_table[0,1]_old = 0.8404813109943889\n",
            "Q_table[(0, 1)]_new = 0.8314506560837723\n",
            "We are on 0 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1998 episode and 1 step\n",
            "Delta Q = 0.9770975822547597\n",
            "Q_table[7,1]_old = 0.7577522847355787\n",
            "Q_table[(7, 1)]_new = 0.7590746385167805\n",
            "We are on 7 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1998 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[11,0]_old = 0.0\n",
            "Q_table[(11, 0)]_new = 0.0\n",
            "We are on 11 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1999 episode and 0 step\n",
            "Delta Q = 0.9845262878800193\n",
            "Q_table[0,3]_old = 0.8138057485318264\n",
            "Q_table[(0, 3)]_new = 0.816951461558663\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1999 episode and 1 step\n",
            "Delta Q = 0.9944324908997348\n",
            "Q_table[0,1]_old = 0.8314506560837723\n",
            "Q_table[(0, 1)]_new = 0.84273808137513\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1999 episode and 2 step\n",
            "Delta Q = 0.9944324908997348\n",
            "Q_table[4,0]_old = 0.9389499394588181\n",
            "Q_table[(4, 0)]_new = 0.9394874364126712\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1999 episode and 3 step\n",
            "Delta Q = 0.9957185126646371\n",
            "Q_table[4,1]_old = 0.9538635444417659\n",
            "Q_table[(4, 1)]_new = 0.9541957026622264\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1999 episode and 4 step\n",
            "Delta Q = 0.9944653745635604\n",
            "Q_table[8,3]_old = 0.9366705408278075\n",
            "Q_table[(8, 3)]_new = 0.9374688613085872\n",
            "We are on 8 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 1999 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rewards_all_episodes = []\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "  state = env.reset()\n",
        "  state = 0\n",
        "  done = False\n",
        "  reward_current_episode = 0\n",
        "\n",
        "  for step in range(max_steps_per_episode):\n",
        "    exploration_rate_threshold = random.uniform(0, 1)\n",
        "    if exploration_rate_threshold > exploration_rate:\n",
        "      action = np.argmax(q_table[state, :])\n",
        "    else:\n",
        "      action = env.action_space.sample()\n",
        "\n",
        "    new_state, reward, done, info = env.step(action)\n",
        "    delta_q = ( 1 - learning_rate)+  learning_rate*(reward + discount_rate*np.max(q_table[new_state, :]))\n",
        "\n",
        "    print(f\"We are on {episode} episode and {step} step\")\n",
        "    print(f\"Delta Q = {delta_q}\")\n",
        "    print(f\"Q_table[{state},{action}]_old = {q_table[state, action]}\")\n",
        "\n",
        "    q_table[state, action] = q_table[state, action]*(1 - learning_rate)+\\\n",
        "                            learning_rate*(reward+discount_rate*np.max(q_table[new_state, :]))\n",
        "    print(f\"Q_table[{state, action}]_new = {q_table[state, action]}\")\n",
        "    print(f\"We are on {state} state\")\n",
        "    state = new_state\n",
        "    print(f\"And now we are on {state} state\")\n",
        "    reward_current_episode+= reward\n",
        "    print(f\"We get {reward} reward \")\n",
        "    print(f\"exploration_rate = {exploration_rate}\\n\")\n",
        "\n",
        "    if done == True:\n",
        "        break\n",
        "\n",
        "exploration_rate = min_exploration_rate +\\\n",
        "                 (max_exploration_rate - min_exploration_rate)*np.exp(-exploration_decay_rate*episode)\n",
        "rewards_all_episodes.append(reward_current_episode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j45ghrMbmYMW",
        "outputId": "35fffbce-d95f-45a7-eead-5c6a38a584b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.31.6)\n",
            "Requirement already satisfied: imageio_ffmpeg in /usr/local/lib/python3.10/dist-packages (0.4.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio) (1.25.2)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio_ffmpeg) (67.7.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install imageio imageio_ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NKpgHiejml6h"
      },
      "outputs": [],
      "source": [
        "import imageio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Vi8Mq4tEl4Yb"
      },
      "outputs": [],
      "source": [
        "def record_video(env, q_table, out_directory, fps=1):\n",
        "  images = []\n",
        "  done = False\n",
        "  state = env.reset(seed=random.randint(0,500))\n",
        "  img = env.render(mode='rgb_array')\n",
        "  images.append(img)\n",
        "  while not done:\n",
        "    # Take the action (index) that have the maximum expected future reward given that state\n",
        "    action = np.argmax(q_table[state][:])\n",
        "    state, reward, done, info = env.step(action) # We directly put next_state = state for recording logic\n",
        "    img = env.render(mode='rgb_array')\n",
        "    images.append(img)\n",
        "  imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "turRjFNxmFal",
        "outputId": "10fb9492-ff9b-4f77-9367-5666dbc96563"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/imageio/plugins/pillow.py:390: DeprecationWarning: The keyword `fps` is no longer supported. Use `duration`(in ms) instead, e.g. `fps=50` == `duration=20` (1000 * 1/50).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/gif": "R0lGODlhAAEAAYUAAP///+v1+Zz3/9/w/8zm/1bj97TI5mjW/z3K8v/CofC1QaHA3auwtJ6qsGOrP0+kuDu+/zK5/zK4/yy1/yip+Syl9SWo/9Ccjs91K71qYoyhtDt9TzGh7yKb9R53v6tRMOZFOa0vRY9NV5dEBok7DFIzP0xohTo/XisrRQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACH5BABkAAAALAAAAAAAAQABAAj/AA0IHEiwoMGDCBMqXMiwocOHECNKnEixokWCBDJq3EgggMcAAEKKHEmypMmPHzmqzChw5UaUJmPKHInSo0uOLW92/Diz58maOjXmvAnTp9GQNQMEZWlA6dKdPotGBepSoNOlHpGCFJkVgNSeSW9afQoVLE+jYas2Jdt15le3VFeOfdpW5lu7cVXOxbq1bte7MdPKXUt3K9y6h1OqvRoU8U/HgfPiJMz2rNbISZPSzBxgr0abHEGTdcl5c2bPfP0aJslZM1fOqBtb9rradGvVpykXVo359urWsUV/Zjw6dGbbNWPr/AqZtu/fsHWnht77NnKUVlFWTusa9/HXH7Mr/y5OfqVrreGbat9NtTv00uA9ihe+PHNG99eZY1c/Xjb3mpfFd55z8vFHX3kIDpicgcQRZd9ORXmn4H6SOfhfhO99h16BAvZH2nfNlTRhZwZ0uJQHKKao4oopbpeUQB0eqBJ8IbIGIHgwbrheffihdSN6ORK4o4U31nidaUEKdhOLTK7o4oIxNjgjiLXhpR+JUU6H4VEjBqlja19+CZiVfXn5mkssUqDmmmxWUEEHHTSJIo8c5kclhvBxeRaWdrqHp4Y+/mXmc38VCeZRBCJlplZorsjmoxS4CaecHtDJZ5R+7nmonoKW2Kehfw44VaeBEhrqj0ctCoBKaUL6aASwxv/q5qwVcMDBpC2aB5KqIpoKKqBG8Wqjr5rmmaqnZhFbqLHBIjsSq466ymasstJa661x5jolAMJ+ap2QqDZbKrFiztasuYhG5m2VIooXErQoSivvq9TWK2m2cw5HIrrp9rpuVO72C9e/YAUssLqY8stawPB6MO/DFNRr75v4VqqvwQf7m7CRXmGc8WYEuwUjaH8GCPJPm00Z4sgNqjhvAQUgIPPMNNM8L6xuqnjfriWSXGxfVTanmsrshsTyzssCrfHStBEt09EQAl0o0yczatzKPbec4ssx1+y1zDdHkHOuWUFdMm1Uv5by1UVzmzXSUittI8JWv6Sw24+F+/GG25b/FORGLj/69cwwCyAAzIPTDDOkY+eLd6+i7k1g3ySpyqzkQ+5skuXAYu5hWZUjC/jWgide+OFdJ47A4o82bvHjw+q9d+agj8R55LN/DhnLCONuFt+6Qjl6vKXLDPPxyB/vdfKpE14ApPliKXTcHGtMO9zpoY0yuAIn/SGU04fZr/fB77eqRoGzqTjzyS/ffs2ssxk979v7PvDk5WcfPvfjx/39fhpJjM8ypiSxlGh0bELczAzHQNR5rYGGO537Ivi8NeWLAEMRoFOqlzcZ6cUAASTTAA9WQLWEsDobbFuyPjeY82WEeGpSoMwg6MCa0VCC8CsABeVnMQyCMCMa1BwJ/ys0mBN2MIUAKIESl8jEJl7nKUMRIuQaREAibgRGLySd8bpGQ8Otr4s1pFkDvaamC0axdrZRSRWvd8UfDqc3HGmiHJk4RQ8KxY1SjJ0ah8jGO54vcFucYRe/2EUZLpCBZKSAGfGIxvjssXtWvKNx4JgRJYrgkhnIpCY1eUkRKPGJOjnjRqZYn/ulUS1/dBgFaHaAA9BwfadroCG3OMvVNW+RNyGlg0zpSBO6RJcEsCQmN7nJTirRMX0UpRGB9yFeMvODqVQTK10JQVjqEIK1RJ77aIbLX+pxl3gB5gdz+c1glqCTxCzmJY8ZNBYyxZ3eKc63xJcepxBPjNV0Hhhpef/N9fGTZrCaH3+a2csnocpP4iEo35SYzoZmkp1XKlZCdXVKg0Z0WXO55yHHqM9B2hKHgfxo8wJqsX15MJ6jmSf/6nnSDJnToQ2F6GwQyiBlSck4U8ojcAiDogcKwJqvdJ42bchAQ8JsAhMw3H3mY9Ob2i2ntdtpUz/CUJgSU4k702l0purOp+I0qlvNok+Bmk9+1lKWzTtqUgWw1Joqiy9QlRCFuFpVq2oSqzvRam6KNlWowq1fGfWA6mJZVltSEJ9BFSS1BjCAsjUFhabya9QA+9gjZqauds2ATCnL16ZKdkxP46lgTXfNxBo2jAjY5yEX21ieddamn71bTKwC2aT/YNaum00XbfvHVRWG1p4eOB3zTIs8L+aQo4NDKmMZtdt09ZaDofPtY25rVXYerLmIeq50Nyda4SaPuMczLiHF+zXlDoC5lXXuc6+b3ux6RJgigKkxSwBd2+lmjZuKHWjnAiujKk+kpt1igGtGLTV6Br+XK9dvR5ku+Mp3nSWw04KX6V6VSni2hOlvWv9b3MIK2MMEjpWB78vH/F6Yu4zp1xxXTMco/XY9kvuYqPgbAQlIQJDsKy0iiXrD5rkPVgx2G1VijODaMBWIR2GxkjUYXRgTGZJvobGNccy+AYOxlusD8gmPTIAnQ9lcXEaUklnMZPt+jm4+0mBpJgora+aY/6xvdl6WRQyViQZ5bu5V83HsTGGTwVeJDAh0oP8cYf2Cic9ITpszDb3mgRKgzULN8Ya9yzx/Oq/AdXb0nauWZhEeWtN91l4SzwlhQQ+a1J4s9Loc27SVeNlE/oGahj9c6eOirtb8pCDytKy/m776S6mB2iNjcuolmpoBTQx0CVUmbI78GlzBftujI6BASv+XkHHO9a2Px2sOefDZy75aszddkmID2tTJZkC47SY9eHLVZFkyD9QgAAFs+/i0ur72RrGZPC23FX9Esym8y0UalrW0NQ1IuMIX3oBAJ7yO8DT4TXs7cHCddN717mg2dYzrfaN11xF4icT/J3BRx3tGI//PX1IYznKHNwDiF0eWHf2TQg6W8FIbmTVps93Rj2/Y3x1JklNp/tdxNehSM7+JBhaugaUr3NRBDI3QERS1oo9Kd3/TiM4HJ+l7Ezbfcxa5zIdOJ6uv8EBIJzuRzB51sdtInoqpLyV9uJWN0BvS7uM5YYe74y0C3YdvT2nct7tCP67NRXnEr+HPJPgR5k40u7U7BPCeQ71z/Lt9t+XfB6V2diPRc5B3VqsR38gvL76iNE9agvVrJslTfnDk3TvmjQtydt+u81FTfefqeHuDlgu0Auo9e3Rvv+CL3vURUJ0gx7ttwvIT6NkTp6Wot3vWi/6Z0/+9bHUkrFNFLumTtQv/xpCPT65ffqjWhJUFLJDojl0/PtpHptqBf6kpxr+d0xHZ+zd0/17lX/z88SwacXfJd0jm53MbBzPqx35dxhXd9zOXA37094DEpzcSKFv7omf8RyZ88WLokhH0RoB5h3lYJlKwQm/t51gqRCMY2FVvhGEreCcxeIG/pYGJwoGy4YGOAYIh+Hoi1WElCHIo2ICXgV0wFzeJ0YEwaIP054KJZ2YVB0kQRydN1h51N4CTFyvKp3wSgz08sVtytz2g9D/RFYX9M4VEUoYmV0VoSIZm9h/vgoXUsoWq04W594WVFYZps27hJxJgSHiLxodRFoBqg2ePN39zVXOGEocSY2OO/ygBEmOHDMZshFhxelhORGJS1GGIMuaEuYcx8hdjfaQvBTJ4PZIRjfiIkBiJmDaJ4laJaxiLppd6oNhOouiJC1J99ldhuNdWvrKLnNKLQedWwahe4Cd2uhg7xiiMmgh8trGM8sRUFnaDwRiNxFgq0JhS0kh4zoiJWLGNJWeGqBcU4KgsnDZ3S1GO5FKISUgW6viL7IiDUHQR9FiP9niP+JiP+riP/NiP/viPABmQAlmPNPdqfChJVOhlB8kUBamQkdRGDflkC0l3lXF1wWhHykFRJpc0F+lUGdk3vEGNZ+eR0gFOidGRBoR7HNONwLYYFbmRSGh0KfmSIcmS0OaShf9hkTKJky5yjhszU2H1VV5FdV4oV/UkWVlFlEWZIbkIdyF5hCPyIiWZkGZoKn0SHEcnjCQHlHuFlHmllHdolKXolJsIlQe1VaPoeevRI9qHHFwGluQRlc2olXB5h27JIBaliFOTMHf5kGppipryKX2ZlnUZcEz5loU5fIeJl4rpM1vCl8Z3cpkYmEaHJGNHmJTSJHmZdpiZmSyymUK3kCzYkZYpmVu5l1eHG6HpiZ75mY1ZJzepE63pJK/JmX4ZlnKTmu/Bec9BTya2Qoryfh7UKtJyL5RiKZzTKOnjKsYpJ8gpela5Ur95ku7HaDJYgfUVIcm5EsTJnBRznJm4nQ3/A0PeiSuaGZ7QSSi+uXq9EZxGF53T2BOqMp6qFDbUYi3XYp49NEnzyRHdKS0Sg5+2op/N1C0/yYLsiWHv2RotFp8z0Z/DQzr2WS20MqAVU6DvR58QE6DWYqE6Q1EGen8Imowodokl0WL9VzCE2DAQM6EcSqAXs6L+KaEtCimsiDPfqS0Q4jGeEzIAuH1itkQ+GhgMM6PkWaPTcqPNeUE7KqMRiqSucqNik6NMylKA2Gkpqn+tdjbyp0QO8KUOYF2M53mhNXroQ6OQUoKJBKBT+qGsdiDLmab3Njhh4zqaYzY/Y4mddXikWKaOGZNdWgJgGqb0BR1Oo6BwiqaPoqY1/1OnFeCmPGOmWXSkizqnX+OokIo3f7qBoSiGktqHfiOcyeilgwqmn+SNpZd1k1qfazJY18SoW8Q4j5orsPOkxfM13rWF8bMmdtplt2eT1ThJoWpZKkSqpUqo0peqonOmlOqqh6V8u6omvVqrzMqq0kRaz+qqsvqhsHNiREY7u5M1vXMjSrQBG3CsX2quYspGueFCBBCnqxRpPGdWXldBPPRvtqo+8so+I7hx0FNS9GM9svM7AMc2vTauRVGu54qu6lqo2EeK2ZOvrbqvHUev7vOv+FqtkOJm/Fp5+harjyJQsqg9xYewEyeVodaSCmuuLNuyLnuqE4lFZ5pAzdNjPv+FVuRFa/aqSD0ks1lEs4hVVPfWYzl7WrvaTUR4RE+IkunoRlG3si4btQ3bkuR4QDO7JoZkszwmtEXrXffKFO5KnlnLbzfLtT9la0fbs07raUu7k1UrrLqkRCEQAiBQt3Z7t3U7t6dKtai0qteqQKr1YVobtIm0SKmkUYDrUYJLtltbuGoLt6haZG9rN5Qkt3SLt5irt6oWm337rlpkS4IEXlc2tJkHNjzrR34br4kruoVEukVbRo9LuXkzbMuYdMrUfhtiuXOLuZk7tyGwtwUFTT8brzLTSuD1daj1TznETWobTcSLAMZbWB2GViO4TTODtLRbsJTjqQ+LkK4WO7r/e7m8a7e++7ub271gO7zTdLw6lq2RZr0yY7jqOzPRi1wAxrjWBL8IgL3Ohqqyi2boS3ctJRJNNLcKoAAYgAEJsMAMvMAJfMCaK6brGVjXGrqZh7y0F15nG1LohwAk5Yvza8Gx17471mGW1sEfPIzuNo6pd5Z4gmgvOGpLZMAIrMANzMAPrAAR7LAdAiSiVcGpJb0knMEgBboiBVARIFDABcSsG1QmLGdHPDMprIkKpb0tfFFS8441sUQXcAEOjAGdJAINHMYJvMBdjFdiuS9iRVRkZb8VG8Tuq1ZKpcJrXH6Rxr5nJbTrg1RzPJewJRtxxZSJSChc7MUJkMBhPMad/1TGCXDGJaBXUglcY3XHQtzBFuxffMxWdOy5k6xtbvw+QYvJa+WLvQVXX5XGRpgwTNTFC6xEDezKjXwBTCR3geWsimu0NXvLhsNaKljHuDrEG4zLQWu/uxwrjKWCtfUcsUXL7fUpq2zIsNzKJWDGsrxEzCzJ2HrLuepxmVfMsHLMruXLE6TNr5rLpuXNEQDOQpbMvrHMV7rOKlbI0vzK0xzLKKpb3VXO03vBGjzORUsz5oVewGVtyEtW/hzMXhPQTZPKuhmO+PzOziHPN0zNswzRQpZFBE3CBm1r/zwzCm0TgZXR7Nu1OqY6H60UDD2SDo0oB9ZgSsTKE23PQupiMP+IitQ2aV2zzyQ9YEj8d76aYTedv/drv4vb0TLTigHU0l+2euyp1EkGX2Ec1ffc1EDtX9WmwUSNb6UbYj590dNm1TmN1Vtd0ImD1EDk1LVbfVQ9ZE+NalEdxvcMcdFl01MWxDlmZa3rqkDnh0Bd1/mm0wgNx/j7y3ttNIz5bKT5horx1IOat75bt4MKvHJtZnR9Y3ZdZSA2unodclvW15b912JdtJpNWoUtZE6G2CNZhdkbIMbqAI69uyAQ2edrcXvmaJTXdWAN2v41Z91m2k5x27gNZx0bUn5HZyp4IABMsOwMEzCMMLBsrujqAOYqzWbJ3LZdgPTacUA43EZc3L3/zWbY/YPcvd3a/XPG7VrIzb3KTayaMW4pO2oLDN0MuwHSLJre9ttBjcuWrN+gfL/M023tZtNXDdrjbHkZDeDujbvfepu95k0xAdV1e8AHXLdwXaiE2eBfHdYEjrbjrcH/zdkYrnMZXeAdfuAgft8O7pAXft8Ht8VuHeESTuHzZScFJ230Zm8H/cajW3ufgXE4ztHN57r8xuP/xq7vFoucUeNWvJTvVQLly0RPPttJLm82nnE6m+P9LcJCS+TD2Go3rnH1ioBCLubQl3KGuY7yF25pVx7hC+W+K9mGhnLLKuCWmt0fq9Vgd2mc/W9xSOeuOq94vm1h1+NjR3VrCaR8/8vnn6oTTdd0TNR0CcdEUKe0UjfnGf7n3F3Ugq7nbtfnl75zmR7oHayAe97ldROXgMm0nT6mQQHpDcBECWduk351d3SFPOiDdu5fYv7Jm1dZ5PfLlrfr/NzrgUd6JlpQnFccTOd0xyZo2Uh3ni6CwN7hwj7CvW7rBCDt/drfsrfPg356i752pcdbVyF8jO50C+dyC1eyQtJ6chjesBfM3S7Wz1fq0ScSv646I1ztZ8vl987CW5mlImTuLSzw1eHutw7vX7PvW07vJmjvsBntWbiFDA/aHOXvER+82Ufb3Qgl7cnx6HKBNaKJApjwdozl+w1y65eC4/fuJw/kb6zyDP9IExRIfd+HiCNf8wYf7mT6o3WR70F8gA2fgAWwgCwPi0Df0fNO9EaftPWnjCAvf/9HpM1snRuIjlVchTuY7T2o8HedvJF2ghCQguj9gVyv7RRbzuZH6kMIMimtYCKZrNurhrV19bObgzB4FzyI9nbuvukXAW2vNkxVEns/8R673Wtf9IA/9k7vWkzYgjS4hCOrXm1YPlo/eBI/h3Q4OHbYaA/SFciH65vvwfWylPB87Ho6ioOYm51Y+YfK15+P7QQo+pvf+bUd+5mvhaPvNbbf3nlo0ZyY6GxThT6J+ktusBM1mueTio8opV3trkiT/FTCiPWiiqsopXtEiUCpaOT/riW1yP3Pjp6A+Zg2TS3W7/yljmTa/6fkP23mr4ron/2vuP3BX2Lef406GaxsocUhj+ga3xgAYcBAAIIFDR4EkFChQYUNHTY0SEDiRIoVCQQQeJDgQ44AGHbkGNHiSIkYB2oE6fBjSogFSZI0qVHmRpUFWdYk+HJkzJkocQa42TKnzoo8EQZdidQlUYpGez61uRAoS5FMCWSEmnVqQpopqzLFqvVpy5tfiYYVO5Ms1aVWBb6FG1fuXLp17d7Fm1fvXr59/f4FHFjwYMKFDR9GnFjx4r9EkwZla5akQMdRIZc96NZA5a6XvWYGu1nnY88hQZ8daPXiVpCkO2p8mVF1/+fXliO3tSjbKs3OvG1/ljxRN1PapovXDi5xeGXMx43jrrh8NGvk1Fufzp1699Te3H9fT35VO3HrD10/HzpSOmfWzsUK1bh+evfqY6XKXJ9+on7VFtXej2+87ehDryf4DpLvpaTc0+pAgxKEyTYGs3KwoPwC8A/D/iL0iauZINxJwvI8ahBABE+CTkGZSjqqu/88tBBF/lSEbbWPXJTpQLQ03LDHEBd8UEYe2RPJJxw7JDFG7OYDzcj2DDRxx9lWtDGqI4+CkSApfeSyKSyT1FLIKWt0skIRYzQxxQzLVApIk9Kccc0WRzTvSzSzjLMiD/bks08/+RwzQDiH5HBOyP+QvBPM8PbLkcRD7QxzUPLYbO5MgdJk6k9N/Qz0REmJtJLOn1y81Ewnb4TyUd5KHfTUUF9skztWWyLpTwpuxTXXCirooINN92TyTVPnRBXWSrmaVVEoXUXyWI+SfU9ZPL90VtiaavUzV20p2LXXXz0IFtoSmaX2NmQNiDUt74y9Kdn60pr2PJDcBcAiW7fVNgJ999213wo44MBbQEMEgN461fWNXZYMHhVeZeXtiOFh7bPvMnrtzRbfXPfl199/A/Z14AwLRrdSdeP9bmEUS2NrYlHPTZllqVwuK6yEMN5TY53z5bjnbkMGllGjZL6OZqpsJto0o71COumalm4NaZz/Pdi5agp69plXoMEVummnZ241ZoguHapY7+qsjdaixCZbQ7M9RFtpqeScF90Z+9y5gAIQ4Ltvv/3eWd9d+2SRZBJZTPjsp+X2kO6I7Xb7VcXXirvxtZ0zvGzJ4V688sMvp7PtqfPe+2/T+Q48gsEH3kj0KrPknPLOP/cSc3oVTlqy425v9GsAR36IVYrw1vb0vvUWQAC9jfdb721XD9rwg8t1WvfyeG/2a+s5wp763FPcveR6JyI+V+YRQF750s93XlvouZa+Ycxl3j54yNOWtrTEC0WTwWlZ3t+PgjQ+iZQPV83TWwIVuLy/LXB9xyvAtoL2Jv/lzzMBlFP/RpS4//nhLzn4uZ/csoeZLPEvUsPj07YQ6EAFms6BLoygtibYNg967zMlFGCMJgKcpXQQPGrKzg5/qDmi1Qg1BCRAznDFQL4lz4nqM90Tk5c+GE4xhrcKmniE+K7C0W9JkxENAXhIRC8uSjhhHGPkivhF9aALhbliIgKkCMW/zZGKDSyAFXOVRcpIJI1dBCAbg+il6lhkjWbsI6MKWZFDAvGM4yMe3xg4x+QhkJJ09NsTTYdFrmmRkM8xZBkdqZwwAvInoQwkIku5mkVSpJF5emQBU0gBSZbukpakZByb6MRNUoCPq5wQocQoSliS8iXTm84NTwnGYy4zQsqET2zcmESq0f+ybwc4wBxXmEcp6hJ9CYSh337ZzGiqCJq/YyZJkGnOojlzkCNZ5zPbWc42QrKafsOmNiGYvid6s4V4FGcnE4lKdMoTf/TMDhBxtKGK5U9JeVpofxp6Kt0oMZNSxKU+FVhJCNYyjvqaIYoMCiaGpsqhYVLok4qZQUgVKywjNSPoEEWsit6zb/qs5S2/ecdaevSBIOWaUWA6Spa66VU7QpgwM7RUVrYKqQgjD1OvpCRZRlEA28TpTsFZRyfGUW8TmEDySvJUdUV1babsCVnTYlYvofVDQkoqWxnlVhBqaE9WxSpG97nVi1oRgWAV60XUKha5soiuAdpgUoWpH4hxbyD/7yLsWYX2MvvZ1QPs42ZW0xdHne6SYwMYQOseW6DItnWypckIZLXCVMRR1iGpJe1qJdta1Grnrszjp15zikk5UvKinw0tUGA7vbLO9nWeGe5lFGvDlCRXVct1bWVludkFajaBHM3oVZkHVtA2zrnpUqzMvmuy8LJsvLdZrnht6wHqblS3WsUuBDW53Ql093DnTWNS1TukV/ZOfqETUH9H+DAAa0hfXt2qe+eb3fiajmOGXI6AvYc7kvGXmP41U90snEqTZvhxBo4AghmoYF7iMasO3heEA3zhAVN4S77r72vFNEwY649autGXBCSwSxZmtsR97eYDYagvVybkxTW2//Fjjoxk5d54xky+oJNBrGMes/DEvbWjkPFI5C0uGcrklXGKDqqU/ObopYxkHJmHaKAz62ubPc4rnDsKwQez8sxF9hwJ16yWO29xdnpWLUr67Mc0Azq2ghYpAdy8Vzn71IovnHMt6yxaMRe6ZXs2M+TUCWUj0sh1BK1xpznkugOXrr18la/6IO1oVSeQyxrcNJNF/aNPo1nWgqxdrfGM5FmvidQhNjU3V53qRsO31Xp7daTy9OVeX65tEIVu7D7ln2crtUr6ddR/YeI6CEAAl/708bB3mWUFcnmskIN2erNtpm2j29rQndy0i1JtE55s3fJuCre9TWwt51bcWA5yuf8jkG9319thxZlJu+fGpSKJrWHUFt9KaRQ5H04L4gqhSKkxW+zd9hPVyB74flgl8ULRFrwXt5yPGl5xZaGcdj1aeXRnba2MA3vjLKxiwB8IcoIvXOU9dLiDXJ7yAalRe20RV0nJWD2kj5Yi3V40DIvt7+r++JvmJuW1JAp031Ul6Vtf+vfS8/VAmbKRZ5zK0yEQdTxOPdxVjy/PKUL2optdlI+MJ6hQ1lhFda9T6+owepKldrYbL+5vJ7FPsZ4ohAYL8BSOkvgaP3EOYljwki+o3gnMd081hPARON8us+vA+Qo815jH4aQkB3k8Mcxs7JI4xKw1vb1/J/YOHxrGJwL/ddDfVLs5fzSqFR8BC1iA0Of6Ye0Rbu3aiWr2P1G+dW4/v+fDJ/p1Uj3TVqZ7ifD+osaj+j+3qa/iH/9ZqAfQ9bXOJO07v1GyJ2pTHet+V/GQPBomTfe7vfbev/m6vB2/COg286O0MoOdH7q/DzNAMLE/5lBATDvAVmKn+cs/Atg//pO6qvOm4RtAGnMU/CKwCAQlB5w/aVsj4mK+41II2GK5c7K4iQszMkm73eO/wgs9FJu0TIu3E3w4GGwIFowuF2w5H1zB0WrBecIUIjQyuDK6z7PBG/QbrGkthgDCrpM+XFPBJRSRPLs7IvGa5bPC6UMpzWETicAaHUNDCcAa/ylEM1/bPhO8t7PzwjeMwzrkMNXLPTg8QgnknzP7D5oww55JQx1bw54JJTfcwj/rwnBhwueKMpITuUaMlUdMQYhzGOtrMkg8N8urDkpkqKdyxEysxHmTRGd5rk9kQtgLOnciDlCcRFFERXhLxAbUDFkkEFoMDVt8kkrpj8G6RDtkRZ1gjGEkxmI0xmNExmRUxmVkxmZ0RsBgj1uLKU9SwjCMP2osFGm8xoESIG0kORD5JALhuxdso1G0O9o7OTAyR/lLvnQsxykxRfRiPnBUpHtLnOeCJXo8R+hzx4SCR3Ppx+gQkGQCSPKSpsVCyC5pPqM6kXU0OTiMvqlCKaXbxf9DaynEokjZcRmJjAnWmiuFnMIzwUiwq0gUhJW0GshoBBuT9C+UdMgsDKaJeissBEnH05EZw0OgQ5VhuUmanKyY8w2ejDyfDEkyDBWhbD2crEmKPJItyUmjDMqw6clpvDadPEqpHEqqTLiqlDaZTJRmQ6Fv+ZO/+0oqcbyoBLP7GDmzpLyrTEsYWUuw/Em3lEehiMv4E0tNIctIQZmn3ME1s8uIY0uDg8gCCUx8yyG6TKPDxL6RuBeN+ZlvYcT/Ipfao0Tk28jH08xxTL/zo0xiWT3mQsfqe7mwnCXI1BrJpDxxoZCTYj1+fL5oIRfOPMDYHBfQHLBO9MyHmBolSh3/jvGYjxGYLFqb+Cmz1myooJCYsKGYwFMZ8JJN52wu9OvNavrNjvEXgBnOTirO5YzI95POuoHO23xNGRtP5AzPDwNEPTlNq8GXQhSc1BQZG/Gam/iA+8RPzzEI/PwAzqvPo4Oa1/hPpgvQkJAa9vRN99wW+FQd+STOhwpCAODP+9TPguBP/6RDKyxQ8xjQ79lQldA1akrQbdnA00md9ykc1zGbEziB+1SAF4XR+2TRGaXRFsVPGFUAGT0BeVHRzanDCiK6h7Sfz3mbH00stWk+8byb9iRRLTOeE60AwrEzTTsug2BRF8XRHP2AGq1R/sRRHeVRKi1SMEyzGQlTIvVR/zKtUMdxLO4TUes8INwSNifFo+eJ0oExzjS50g/I0iy9zwcA1EDF0j59UR09x+6hzVgBHvNkSW1c1B8UH9NUITn1q9BrH1250+hB1ADYU0KN0Q8IVEHlU0/VUhY9VPQrT1gsziFtVF4Dn+uZJlkaUWvyKY7TKnCToKCiIdPoVAXAAAzwUhj9Vf781S/Fz2Hd0hNYSGU7UgtqstSTKWatoUTlnA8SFEktHkbDubYTvm/K1XMDRoLoVWQdVF8F1mPFAGO9T2Q11bmkoGbNzXayVk+poHid1ne7VvKBU84KMqvyuAb7Jj3ClXEyv4fY02I1V2I9V2NF1l91WAwYgRFoV/9p8jMU3EeDDI2K7cE9TMIjeqMleqAs89eu4qacu1RfEig0AomDTdeERddyXddzfdhfjdiJTScPtFh2pMRvVFku0llR5Fl7sqhvGrf3yi2PG9leIth6bAiWnVmHVVhyRVdkBVSbbaNVzbuCBdpK5MZgArWt9dg3vZWeArgFC9hc0jKzRR2UPSOsVQinfdpzjVmpndtzrVplFUZgSqwZ6S/UcNvJ69u8taexvaZsMtr/Q1puDae+WVqCYlFAvU8SkNzJpVzJ5c/Kndw/DVQWzcdV2jVofVQuDA9u/FySmkBLG91pGlq+yafDPVoA1KrF5ZvGtTUAeNwHiFzMrdzL1V3/zb3bziWnzAtdRUzd4AXdvyVeR6opwi3aw9Mp90Ign4rCCAiplLrdUDUBE5jQD3hahc3eUP1dmkq0R6XKohTJhBk0pjXdvbwSuFwv5i3b3ztbjfq/6I3dvgGqTYS26w3U7N3e7kXX7wVfzhXflJq8szzfdUnfw2LKi0Tf9cKrvbIu8fO9Sq0lwBIA/YUK/gVUHEXWPo3ZPg1VFt07X8yKwlqNw2pIeEPhsHPJquKqvDLbf0vcCw6rDBasVDwIDn4AD15YP+XelsXRET6BEtbh0lIRqVIpxGLhylBiU6kpzOqss+XXrEoe4CrA5+BfEP6A7O1T/w1iEX4AEp7OvYUq/+Oi1vNaLo9MYwimVN/iNyAz2yveF9DK4unZYiD24iwFY4Qd4jEu4jIONKhg41UMs0F+ikLew5o6tdfNK+CTX9PhrgHwrtFKCRbNXgDO3j3G0U3e5LjFADLWMA5Tt9qK0O9MTshg5DklscPjqVQDWL+Z5EqmLEw2AU3e5C/25FuOW1F+wJ0tL1Mm5WBGLu3QuL1iNbWdX6vDwZBzpQjjCFv25F+VZl5+2F3+ZAzwZALWsNLFR04MwQ/z5vOMGRczZptDZmNTZkdmnjp75hUz2BPAZmqW52y+Zmzm5W3e0QIbZ/JqMXCusH6Wx3/OTRyLACrrrR67sksqUUlzZhrzsv+GQAEU4FIanWjMneiKntGJ/h9IBY0v++YYXAqQBq8wC0SEDr5WjuT4teDTkbvji2iFyGiNPoGLrtyZ1miOdtYKEwmSfkst7GmfXkyPHgq26zEKdi+3Q6Ac5GlheoiJxuddftqo9uSJppD0HTNDY0lEqzQuFMLMbOpA9L9hS+ptJVuHTrawrt2EgGqqzuSZdevstWqoUOtxPkLqaxCstrSvZk6b+LURY+VubeSP+z8HSrZ3jTUAaGu3nuq4nuj5CFGttcbpi2ychTG5RJy/DraU7rfARurCXqDDrmyJRoG4tmaHNe3H9jQq/drJHkVYgydO80nY7rZv62yPo+DmJVn/04vE9V2biQblhp3Zun3auYYoektMe1u+ZnvXdCuv5RYkxLbAfdstcMPtbmXo0H7o5sZX4A5u4pbZ4Dbud0Puojq4K2Tu8o5W5Ubv6BaeiThm8DtqSA6+pd7utSSJBVgA7wZl8Abvhx1vM8VvhrPKb3Y5TQQdIf0jUnTT+Hbp+TYxnbPvngvSidBv/o5b/w5iUA7wxRrwnzNKA2fwCi+7LFxwgptB/XvCW12g0YM7+X3prENSC9/v0o7rxnbridZveqI71btYVRWP9au7n71DUkrx6V7xo945xENcGC8ArAvyGZeIC7dxxoZrx0aBHS+oHmePHz9FGfe5IefYeBo8/xpc8e+D5WPzseE7vRGkctPGcarW8QUgLr8rusqz175D1Wvkys1bxc5zU+8LPefd7SZn867Z86F48xu/8hzPcjofFTvPSfUbI0nXvNasdDr8PDSH5H8TuPLzQNLMEv2m8ok29VNH9VRX9UfXcgFFv9qkayHPxqh5dQb08+XLPlq3jU33Pfm+bnADOVAfm1o3CFKv8VVH9mRndUh39XbE9DCf9WbXzWcncdBpvwq8QBtUaNjlQAggQOGy5Ocw9nEn93I3d2O/WBD8Q9yLP9sJ91aFv9vDv+/QP0Ef6zmVb5DrQLJQ94I4938HeHQnci1cwHh/7QIreHaXd/VskiPnvdUzh0I25DMjPGXUxUIlo3gN7cFoJ3hgjLKc5fimbribMfN9gcJ2NsSqzOIxT95Fwfi/DCSQ70aPLsyP3/iZL0Kr3MnxOcNBZFAoHyZEvMWVFLuDh1CN9HggX006VNOix0M/BE+S7/k0/PmHJjShL0mil0NGnEWtX8Sl7/qaV/o+POJySdTyzWGA5scvnw1XjEdelCi3L0hFjfuyJ42z53MN5ky8R3CnMGRbZ/vdkHse8sS610Wkz9q8PXyvT/yDtEXED0bHl0XIP2AwesbLx/zM13zACAgAIfkEAGQAAAAsEQBNAB0AZgCF////6/X5nPf/3/D/zOb/VuP3tMjmaNb/Pcry/8Kh8LVBocDdq7C00JyOnqqwY6s/O77/jKG0T6S4O31PMrn/Mrj/LLX/KKn5LKX1Jaj/MaHvIpv1z3UrvWpiq1Ew5kU5rS9Fj01Xl0QGiTsMUjM/Hne/TGiFOj9eKytFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACP8AAwgcSLCgQAAADBJEyLChw4QBGiqM+LAiRIkKLzo8WJEjQoEECGjEaNEjxJAWU6o0qbLlR4MuH3LMGJMkxIEhWda8CZLAQRJAgwodihFnyJBDkwqV2ZMA0BBQO0idOhVqCKBFjz6NSpWqVaAzm24N0dUrVLAUeTolUbatVLQHCa512xauQqB0ywLNeZdtXqp7ffb9C5jERIF4Cb81PJDhwMSK0W5ETMIq3a+MLY69fJaESqWgl6YMTfozadCTGY4FyqB169WebQKA7fp15c4qbQetzWBo64UOdbOu7ZvB4YEOkitf7qB1cqYGmUt37uDh0esEIiyPoF15bevYj8r/FayzYXjyAfjWPD++fMXzfIEfbxoeJs/5E5nCj59/8n7yL7kXYHrYNcbTSkZdF5NOBqHkEoMF5bRTSgVNWJKBjmG4oIYH7oRfWiNRGIABJJZo4okopqjiiiyWaCGCIF4ooGMPcvgecC/JqBB6sk02kXg7ohcWRkA2KCRFJtFXZIUhglcgTTMaaN9x0A0YVn9FfYiklhOJRqVLollpY0Vh3tcYhEA9oOYDkmWIEpokrMlmZm6KpFmccq6JVWp35qlnbFkaCNQEE/ipJqFt0jRooYYiSmeEaxEq6aSUOmolUiRUqqmke0IKFAggfCDqqKSKCuqeAWIKaqmsfnAqoDd98gpqqK2SOisInVJ2a622zrrnUKAqoAAHHCRg7LHGEivsq0oFO2yxyB6rrALMCtVAA8lyYFUIyG5LrLHXDnVtttt2a9W3CYTLWADWYpsAUMjCm24DQhXUrrHy4ksCuPQG5dG97+57rLzqojogUONGy69do5GQsMLqxjTWthQb3DDFGF8FK5l4qmnqrKLKaTFHaa758aofiLwxyQITaugDhOrbsLEuNzqBvjgiNLGowgor6rZ22XsbVDz3/DNmgerqa1C3WgzAebJW2/TGT1/HHXdCcZecUN8xhJ3WDgiVnHBdI3Tedt3x5pqTVne3HHXLGRQQACH5BABkAAAALBEAjQBaACYAhf///+v1+Zz3/9/w/8zm/1bj97TI5mjW/z3K8v/CofC1QauwtNCcjqHA3Z6qsDu+/2OrP4yhtE+kuDt9TzK5/zK4/yy1/yip+Syl9SWo/zGh7yKb9c91K71qYqtRMOZFOa0vRY9NV5dEBok7DFIzPx53v0xohTo/XisrRQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAj/AAMIHEiwoEAAAAwSRMiwoUOGBgw8nGiQhMWLGC8GQKhwoseDDBUW9NgwQMSBJCdmXGlxY8iFKUu65CgSZUyTBmzGZMhy5cyEC0HK/PhTIIGjSGFOjAj0KMynAS5OmEp1KgQIGIsCfSjUYVejSJ3qfMgULFSQAqVWpXo1a8mdcGmCDdsVokSuHR9arHq1b1+LcQPLDRBW7NK7XvM63MvW718SMsfGRTuwcFKDZX8OBbqQsVXHfltyrguX8tzCCjMTHXzQ8wTQoUlsrEyA9OSClnNHRJrSoFPXn2FjlW1Wc2DfuQvvPtobd23gr4UPpx1WcGTqyZdfJjrX9Yfv4MN//295mrl11oSTH9VumCJ17+Ljk0+f3PZLvOXDsi+Mn75FEACCEJ98xNGXm3009afeftUl1h0JAQo4YHiAEaTegTVdZ9pJ+bU3GAH/RQiCAgpwwEECKCbAAAMVYnehWCJp6NJAHBpIV1GVhRghiSamqCKLBVr4Yn7FyUhjTjUlmRYJPq5oYghQhuDjfEJeSGR6X4lUo5IiWdQkA09GOWWQNVl2mlJxncQdlxatuOKYY3JpY20GogmXmu7J2aabcKYIGHpyjnQenoIVtOebfjKZ6EuBxjhoTucpZJGJiMZpHKMZ5inoYQaex9GkHFS6aHNJrmlnQyc1GKlFUbYawp+eRuK6KUJbpucpq65CCWushc4KQK3mBcaYX1MBOB5kCR53Kaal1mjZag0N21exEsKKoHukKvkrknNCyxMJfEGA4me78orei3Ti1FRucLl21bjRVWgus3OaKVBmybVLQq5Qfkdii43aRJpI9WXWYbpd7suvvwr8GbDAxhF8oMH1IlyTjiKKhpB6Qp5q6pzq0oRufRhHuCvHtHmsKZFMiTwyUhHE7MDMPS1g880YFjlvlS2/9DIBEcw8cwQ132xzzlgu2+tcPbv8cgBCy+yA0VRvXJ+gXO5UUNOYjhy00DPbDLbQAgUEACH5BABkAAAALFEAjQAdAGYAhf///+v1+Zz3/9/w/8zm/1bj97TI5mjW/z3K8v/CofC1QauwtKHA3Z6qsDu+/0+kuGOrPzK5/zK4/yy1/yip+Syl9SWo/9Ccjs91K71qYoyhtDt9TzGh7yKb9R53v+ZFOatRMK0vRY1cM49NV5dEBlIzP0xohT5Uajo/XisrRQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAj/AAMIHEiwoEAAAAwSRMiwocOEARoqjPiwIkSJCi86PFiRI0KBBAhoxGjRI8SQFlOqNKmy5UeDLh9yzBiTJMSBIVnWvAmSgM6aBUMKFbkTY4ChKIsyxIl06M+lFJk2zUmxZFWCU7P6zIhVa9OJCr1S/TpR7FayYLs6PSo0bVikPal6dEu36su6YFvSVbpXqd+/Lp9aTSm4o13AhAciNooX5kiojWceBqC168KUlZletjjV8mTOaNkWbpj5Mt3SinlGTo3Rq1uZbLOm3mw4blvJhdUKjanTYFK9k337XHx3NG/WxYvS5qm878vAAQxIn069uvXr2LNrn07cKHTjnzci/+dM+2narSbNg70t3HH62GXRz7Zrm33B55hDmw5/tzhumt6pFlVe4jXm32oBlKBgCQduBsKDEDa0IIOQBQAhCAxd+KCECzJ2IQoPKiDiiA8qCMGJECiIAogQjqgAiy6KWGIJKKZYwooXughCjCOaWCOKCvIoo5AK+PijjUTuqAAGGMy4wQZHnvhkkApoKCKTTkIZ5ZQlyHghkyIq+OSYZJbJJZNYgllkCWa2OaaCaDYZp4IhhPDBnXjmeWedcKIJwpwl1KnnoB/wWUKcD8xYp6CE5rloCAo+mCgIdC7aqKOLRkrphHVeiUECoIYKqpqGTrhgp0t+KmqopEJqagkXXPcwKgYj1DqCqLaOwCSosZoa66y54mrrrgn0WsIDyE74awIKitpssRdMKCKyDygrK7MlOJsttNIqYAKT1oL6rLjbGtvnt3FioOCyq3JbggnoMgnvvODCem27xs6Lrr7oKpjrv7YqqC+TKaxoMAr+AvyvigejULDBRkKwp6Uf1MjwiinoG/HEjFr87rwZz/vsk1FC8CS5+oYM78haHnkytilrXEKud7p4Z64CgwwozR/Y/AHOh6KZQrrqBprpqUcTPXS6lZZqtKFKxynC1CJMSHXVC14dp8omnOD1CVZTPeHXJ8TML9leXz012fyawDW8aJ+gtghs8xsQADs=\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "video_path=\"/content/replay.gif\"\n",
        "video_fps=1\n",
        "record_video(env, q_table, video_path, video_fps)\n",
        "\n",
        "from IPython.display import Image\n",
        "Image('./replay.gif')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}